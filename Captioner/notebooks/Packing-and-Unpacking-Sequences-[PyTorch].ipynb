{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Reference](https://gist.github.com/Tushar-N/dfca335e370a2bc3bc79876e6270099e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run LSTM on a batch of following 3 sequences\n",
    "seqs = ['tiger', 'bear', 'dog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<PAD>', 'a', 'b', 'd', 'e', 'g', 'i', 'o', 'r', 't']\n"
     ]
    }
   ],
   "source": [
    "# 1. Construct vocabulary\n",
    "vocab = ['<PAD>'] + sorted(set(sum([list(seq) for seq in seqs], [])))\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9, 6, 5, 4, 8], [2, 4, 1, 8], [3, 7, 5]]\n"
     ]
    }
   ],
   "source": [
    "# 2. Load indexed data\n",
    "vectorized_seqs = [[vocab.index(s) for s in seq] for seq in seqs]\n",
    "print(vectorized_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Create an LSTM\n",
    "embedding = nn.Embedding(num_embeddings=len(vocab), embedding_dim=4)\n",
    "lstm = nn.LSTM(input_size=4, hidden_size=5, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 4, 3])\n",
      "tensor(12)\n"
     ]
    }
   ],
   "source": [
    "# 4. Pad sequences with 0's till max lenght sequence\n",
    "seq_lengths = torch.LongTensor(list(map(len, vectorized_seqs)))\n",
    "print(seq_lengths)\n",
    "batch_sum_seq_length = sum(seq_lengths)\n",
    "print(batch_sum_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "# 5. Create a placeholder tensor initialized with zero\n",
    "seq_tensor = Variable(torch.zeros((len(vectorized_seqs), seq_lengths.max()))).long()\n",
    "print(seq_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9, 6, 5, 4, 8],\n",
      "        [2, 4, 1, 8, 0],\n",
      "        [3, 7, 5, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "# 6. Populate placeholder with data\n",
    "for idx, (seq, seq_len) in enumerate(zip(vectorized_seqs, seq_lengths)):\n",
    "    seq_tensor[idx, :seq_len] = torch.LongTensor(seq)\n",
    "    \n",
    "print(seq_tensor)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.1774, -0.6650, -1.9646, -0.5543],\n",
      "         [ 1.5618, -0.2271, -1.0775, -0.0864],\n",
      "         [-1.4178,  0.2782,  0.3966,  0.3674],\n",
      "         [-0.8248,  0.6535,  0.2662, -0.6617],\n",
      "         [-0.2790, -1.5629, -1.4913,  1.2494]],\n",
      "\n",
      "        [[ 0.3114,  0.4633,  0.6923,  1.6583],\n",
      "         [-0.8248,  0.6535,  0.2662, -0.6617],\n",
      "         [ 0.0282,  1.3601, -0.3172,  1.6066],\n",
      "         [-0.2790, -1.5629, -1.4913,  1.2494],\n",
      "         [-1.8080,  1.9751,  1.2385, -1.0715]],\n",
      "\n",
      "        [[ 0.1876,  0.1366, -0.6343, -0.3525],\n",
      "         [-0.5165, -0.6756,  0.9496, -0.2688],\n",
      "         [-1.4178,  0.2782,  0.3966,  0.3674],\n",
      "         [-1.8080,  1.9751,  1.2385, -1.0715],\n",
      "         [-1.8080,  1.9751,  1.2385, -1.0715]]])\n"
     ]
    }
   ],
   "source": [
    "# 7. Get embeddings\n",
    "embeddings = embedding(seq_tensor)\n",
    "print(embeddings.data)\n",
    "# Row group-0: tiger\n",
    "# Row group-1: bear (last row is <PAD>)\n",
    "# Row group-2: dog (last 2 rows are <PAD>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 3, 3, 2, 1], grad_fn=<PackPaddedBackward>)\n",
      "tensor(12, grad_fn=<SumBackward0>)\n",
      "torch.Size([12, 4])\n",
      "tensor([[-0.1774, -0.6650, -1.9646, -0.5543],\n",
      "        [ 0.3114,  0.4633,  0.6923,  1.6583],\n",
      "        [ 0.1876,  0.1366, -0.6343, -0.3525],\n",
      "        [ 1.5618, -0.2271, -1.0775, -0.0864],\n",
      "        [-0.8248,  0.6535,  0.2662, -0.6617],\n",
      "        [-0.5165, -0.6756,  0.9496, -0.2688],\n",
      "        [-1.4178,  0.2782,  0.3966,  0.3674],\n",
      "        [ 0.0282,  1.3601, -0.3172,  1.6066],\n",
      "        [-1.4178,  0.2782,  0.3966,  0.3674],\n",
      "        [-0.8248,  0.6535,  0.2662, -0.6617],\n",
      "        [-0.2790, -1.5629, -1.4913,  1.2494],\n",
      "        [-0.2790, -1.5629, -1.4913,  1.2494]], grad_fn=<PackPaddedBackward>)\n"
     ]
    }
   ],
   "source": [
    "# 8. Use pack_padded_sequence with embeddings and sequence lengths\n",
    "packed_seq = pack_padded_sequence(embeddings, seq_lengths.numpy(), batch_first=True)\n",
    "print(packed_seq.batch_sizes)\n",
    "print(torch.sum(packed_seq.batch_sizes))\n",
    "print(packed_seq.data.shape)\n",
    "print(packed_seq.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Output**\n",
    "\n",
    "```\n",
    "[[-0.4805,  0.7362,  0.2114,  0.2493], >>> t\n",
    " [-0.9830,  1.2551, -2.0148, -0.5703], >>> b\n",
    " [-1.4842,  0.1411, -0.5256, -0.0952], >>> d\n",
    " [ 1.8393,  0.3635, -0.0469, -0.6119], >>> i\n",
    " [-1.9377,  0.3498,  0.5100, -0.4590], >>> e\n",
    " [ 1.3814,  1.2770, -0.2290, -0.5498], >>> o\n",
    " [ 0.3315,  0.1699, -0.5243, -1.0015], >>> g (tig)\n",
    " [ 0.2993, -0.2961,  1.9194, -0.2453], >>> a\n",
    " [ 0.3315,  0.1699, -0.5243, -1.0015], >>> g (dog)\n",
    " [-1.9377,  0.3498,  0.5100, -0.4590], >>> e\n",
    " [-0.4022, -1.2878, -2.3163,  1.8120], >>> r (bear)\n",
    " [-0.4022, -1.2878, -2.3163,  1.8120]] >>> r (tiger)\n",
    "```\n",
    "\n",
    "\n",
    "| 3 | 3 | 3 | 2 | 1 |\n",
    "|---|---|---|---|---|\n",
    "| t | i | g | e | r |\n",
    "| b | e | a | r |  |\n",
    "| d | o | g |    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 3, 3, 2, 1], grad_fn=<PackPaddedBackward>)\n",
      "torch.Size([12, 5])\n",
      "tensor([[ 0.0774, -0.0159,  0.1193, -0.0523, -0.0840],\n",
      "        [ 0.0189,  0.0229, -0.2914, -0.1422,  0.0426],\n",
      "        [ 0.0213, -0.0601,  0.0458, -0.0714, -0.0969],\n",
      "        [ 0.0902,  0.0247,  0.1746, -0.0165, -0.0758],\n",
      "        [-0.0566, -0.1729, -0.1680, -0.2349, -0.1319],\n",
      "        [-0.0881,  0.0057, -0.2034,  0.0713,  0.0363],\n",
      "        [ 0.0341, -0.0562, -0.1220, -0.1587, -0.1454],\n",
      "        [ 0.0685, -0.2064, -0.3035, -0.1166, -0.1028],\n",
      "        [-0.0808, -0.0834, -0.3579, -0.1623, -0.0402],\n",
      "        [-0.0367, -0.1843, -0.1064, -0.1851, -0.2191],\n",
      "        [ 0.1139, -0.0036, -0.2462, -0.1719, -0.0392],\n",
      "        [ 0.0840,  0.0177, -0.1714, -0.1227, -0.0618]], grad_fn=<CatBackward>)\n"
     ]
    }
   ],
   "source": [
    "# 9. LSTM forward pass\n",
    "packed_output, (h, c) = lstm(packed_seq)\n",
    "\n",
    "print(packed_output.batch_sizes)\n",
    "print(packed_output.data.shape)  # 12 x LSTM output size\n",
    "print(packed_output.data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 4, 3])\n",
      "tensor([[[ 0.0774, -0.0159,  0.1193, -0.0523, -0.0840],\n",
      "         [ 0.0902,  0.0247,  0.1746, -0.0165, -0.0758],\n",
      "         [ 0.0341, -0.0562, -0.1220, -0.1587, -0.1454],\n",
      "         [-0.0367, -0.1843, -0.1064, -0.1851, -0.2191],\n",
      "         [ 0.0840,  0.0177, -0.1714, -0.1227, -0.0618]],\n",
      "\n",
      "        [[ 0.0189,  0.0229, -0.2914, -0.1422,  0.0426],\n",
      "         [-0.0566, -0.1729, -0.1680, -0.2349, -0.1319],\n",
      "         [ 0.0685, -0.2064, -0.3035, -0.1166, -0.1028],\n",
      "         [ 0.1139, -0.0036, -0.2462, -0.1719, -0.0392],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0213, -0.0601,  0.0458, -0.0714, -0.0969],\n",
      "         [-0.0881,  0.0057, -0.2034,  0.0713,  0.0363],\n",
      "         [-0.0808, -0.0834, -0.3579, -0.1623, -0.0402],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "# 10. Pad packed sequence\n",
    "output, input_sizes = pad_packed_sequence(packed_output, batch_first=True)\n",
    "print(input_sizes)\n",
    "print(output.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "scores, _ = lstm(embeddings)\n",
    "print(scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
