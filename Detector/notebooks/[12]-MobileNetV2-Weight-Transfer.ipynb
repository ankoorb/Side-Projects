{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_divisible(v, divisor, min_value=None):\n",
    "    \"\"\"\n",
    "    This function makes sure that number of channels number is divisible by 8.\n",
    "    Source: https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n",
    "    \"\"\"\n",
    "    if min_value is None:\n",
    "        min_value = divisor\n",
    "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_v < 0.9 * v:\n",
    "        new_v += divisor\n",
    "    return new_v\n",
    "\n",
    "\n",
    "class ConvBnReLU(nn.Module):\n",
    "    \"\"\"\n",
    "    [CONV]-[BN]-[ReLU6]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, inCh, outCh, stride):\n",
    "        super(ConvBnReLU, self).__init__()\n",
    "        self.inCh = inCh  # Number of input channels\n",
    "        self.outCh = outCh  # Number of output channels\n",
    "        self.stride = stride  # Stride\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(self.inCh, self.outCh, 3, stride=self.stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(outCh),\n",
    "            nn.ReLU6(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class InvertedResidual(nn.Module):\n",
    "    \"\"\"\n",
    "    [CONV_1x1-BN-ReLU6]-[CONV_3x3-BN-ReLU6]-[CONV_1x1-BN] with identity shortcut.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, inCh, outCh, t, s):\n",
    "        super(InvertedResidual, self).__init__()\n",
    "        self.inCh = inCh\n",
    "        self.outCh = outCh\n",
    "        self.t = t  # t: expansion factor\n",
    "        self.s = s  # s: Stride\n",
    "        self.identity_shortcut = (self.inCh == self.outCh) and (self.s == 1)  # L:506 Keras official code\n",
    "\n",
    "        # Bottleneck block\n",
    "        self.block = nn.Sequential(\n",
    "            # Expansition Conv\n",
    "            nn.Conv2d(self.inCh, self.t * self.inCh, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(self.t * self.inCh),\n",
    "            nn.ReLU6(inplace=True),\n",
    "\n",
    "            # Depthwise Conv\n",
    "            nn.Conv2d(self.t * self.inCh, self.t * self.inCh, kernel_size=3, stride=self.s, padding=1, \n",
    "                      groups=self.t * self.inCh, bias=False),\n",
    "            nn.BatchNorm2d(self.t * self.inCh),\n",
    "            nn.ReLU6(inplace=True),\n",
    "\n",
    "            # Pointwise Linear Conv (Projection): i.e. No non-linearity\n",
    "            nn.Conv2d(self.t * self.inCh, self.outCh, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(self.outCh),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.identity_shortcut:\n",
    "            return x + self.block(x)\n",
    "        else:\n",
    "            return self.block(x)\n",
    "\n",
    "\n",
    "class PointwiseConv(nn.Module):\n",
    "    def __init__(self, inCh, outCh):\n",
    "        super(PointwiseConv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(inCh, outCh, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(outCh),\n",
    "            nn.ReLU6(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "# MobileNetV2\n",
    "class MobileNetV2(nn.Module):\n",
    "    \"\"\"\n",
    "    MobileNetV2 feature extractor for YOLOv3. NOTE: YOLOv3 uses convolutional layers only!\n",
    "\n",
    "    Input: 416 x 416 x 3\n",
    "    Last layer Pointwise conv output:13 x 13 x 1024 -> Large object detection\n",
    "    5th layer Pointwise conv output: :26 x 26 x 512 -> Medium object detection\n",
    "    3rd layer Pointwise conv output: 52 x 52 x 256 -> Small object detection\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, params):\n",
    "        super(MobileNetV2, self).__init__()\n",
    "        self.params = params\n",
    "        self.first_inCh = 3\n",
    "        last_outCh = 1280\n",
    "\n",
    "        self.c = [_make_divisible(c * self.params.alpha, 8) for c in self.params.c]\n",
    "        # Last convolution has 1280 output channels for alpha <= 1\n",
    "        self.last_outCh = _make_divisible(int(last_outCh * self.params.alpha),\n",
    "                                          8) if self.params.alpha > 1.0 else last_outCh\n",
    "\n",
    "        # NOTE: YOLOv3 makes predictions at 3 different scales: (1) In the last feature map layer: 13 x 13\n",
    "        # (2) The feature map from 2 layers previous and upsample it by 2x: 26 x 26\n",
    "        # (3) The feature map from 2 layers previous and upsample it by 2x: 52 x 52\n",
    "\n",
    "        # Layer-0\n",
    "        self.layer0 = nn.Sequential(ConvBnReLU(self.first_inCh, self.c[0], self.params.s[0]))\n",
    "\n",
    "        # Layer-1\n",
    "        self.layer1 = self._make_layer(self.c[0], self.c[1], self.params.t[1], self.params.s[1], self.params.n[1])\n",
    "\n",
    "        # Layer-2\n",
    "        self.layer2 = self._make_layer(self.c[1], self.c[2], self.params.t[2], self.params.s[2], self.params.n[2])\n",
    "\n",
    "        # Layer-3\n",
    "        self.layer3 = self._make_layer(self.c[2], self.c[3], self.params.t[3], self.params.s[3], self.params.n[3])\n",
    "        self.layer3_out = nn.Sequential(PointwiseConv(self.c[3], 256))\n",
    "\n",
    "        # Layer-4\n",
    "        self.layer4 = self._make_layer(self.c[3], self.c[4], self.params.t[4], self.params.s[4], self.params.n[4])\n",
    "\n",
    "        # Layer-5\n",
    "        self.layer5 = self._make_layer(self.c[4], self.c[5], self.params.t[5], self.params.s[5], self.params.n[5])\n",
    "        self.layer5_out = nn.Sequential(PointwiseConv(self.c[5], 512))\n",
    "\n",
    "        # Layer-6\n",
    "        self.layer6 = self._make_layer(self.c[5], self.c[6], self.params.t[6], self.params.s[6], self.params.n[6])\n",
    "\n",
    "        # Layer-7\n",
    "        self.layer7 = self._make_layer(self.c[6], self.c[7], self.params.t[7], self.params.s[7], self.params.n[7])\n",
    "\n",
    "        # Layer-8\n",
    "        self.layer8 = nn.Sequential(PointwiseConv(self.c[7], self.last_outCh))\n",
    "\n",
    "        self.out_channels = [256, 512, 1280]\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _make_layer(self, inCh, outCh, t, s, n):\n",
    "        layers = []\n",
    "        for i in range(n):\n",
    "            # First layer of each sequence has a stride s and all others use stride 1\n",
    "            if i == 0:\n",
    "                layers.append(InvertedResidual(inCh, outCh, t, s))\n",
    "            else:\n",
    "                layers.append(InvertedResidual(inCh, outCh, t, 1))\n",
    "\n",
    "            # Update input channel for next IRB layer in the block\n",
    "            inCh = outCh\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        out52 = self.layer3_out(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        out26 = self.layer5_out(x)\n",
    "        x = self.layer6(x)\n",
    "        x = self.layer7(x)\n",
    "        out13 = self.layer8(x)\n",
    "        return out52, out26, out13\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "                \n",
    "                \n",
    "def MobileNet(pretrained=True, **kwargs):\n",
    "    \"\"\"\n",
    "    Constructs a MobileNet V2 model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    pretrained: bool, use ImageNet pretrained model or not.\n",
    "    n_class: int, 1000 classes in ImageNet data.\n",
    "    weight_file: str, path to pretrained weights\n",
    "    \"\"\"\n",
    "    weight_file = kwargs.pop('weight_file', '')\n",
    "    model = MobileNetV2(**kwargs)\n",
    "    if pretrained:\n",
    "        state_dict = torch.load(weight_file)\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config():\n",
    "    \"\"\"\n",
    "    Configuration for training MobileNetV2-YOLOv3 model\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # MobileNetV2 parameters\n",
    "        # ----------------------\n",
    "        # Conv and Inverted Residual Parameters: Table-2 (https://arxiv.org/pdf/1801.04381.pdf)\n",
    "        self.t = [1, 1, 6, 6, 6, 6, 6, 6]  # t: expansion factor\n",
    "        self.c = [32, 16, 24, 32, 64, 96, 160, 320]  # c: Output channels\n",
    "        self.n = [1, 1, 2, 3, 4, 3, 3, 1]  # n: Number of times layer is repeated\n",
    "        self.s = [2, 1, 2, 2, 2, 1, 2, 1]  # s: Stride\n",
    "        # Width multiplier: Controls the width of the network\n",
    "        self.alpha = 1.0\n",
    "        \n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MobileNet Pre-trained on ImageNet - Weight Transfer\n",
    "\n",
    "\n",
    "[Example](https://github.com/lizhengwei1992/mobilenetv2_deeplabv3_pytorch/blob/master/utils.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of keys (pre-trained):  267\n"
     ]
    }
   ],
   "source": [
    "# Model pre-trained on ImageNet weights\n",
    "trained_state_dict = torch.load('./MobileNetV2.pth.tar')\n",
    "trained_keys = list(trained_state_dict['state_dict'].keys())\n",
    "print('Number of keys (pre-trained): ', len(trained_keys))\n",
    "trained_weights = list(trained_state_dict['state_dict'].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of keys (modified):  330\n"
     ]
    }
   ],
   "source": [
    "# Modified MobileNet\n",
    "model = MobileNetV2(params=config)\n",
    "model_keys = list(model.state_dict().keys())\n",
    "print('Number of keys (modified): ', len(model_keys))\n",
    "model_weights = list(model.state_dict().values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'layer0.0.conv.1.num_batches_tracked'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ignore_indices = [i for i, k in enumerate(model_keys) if k.endswith('num_batches_tracked')]\n",
    "ignore_indices += [114, 115, 116, 117, 118]  # layer3_out weights not in MobileNetV2 pretrained on ImageNet\n",
    "ignore_indices += [246, 247, 248, 249, 250]  # layer5_out weights not in MobileNetV2 pretrained on ImageNet\n",
    "\n",
    "print(330 - len(ignore_indices))\n",
    "model_keys[ignore_indices[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, w in enumerate(model_weights):\n",
    "#     if i not in ignore_indices:\n",
    "#         if len(list(w.size())) > 1:\n",
    "#             print(i, w.size(), '---> ', model_keys[i])  # 114 to 118? 246 to 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, w in enumerate(trained_weights[:-2]):\n",
    "#     if len(list(w.size())) > 1:\n",
    "#         print(i, w.size(), '---> ', trained_keys[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([32, 3, 3, 3]) --->  layer0.0.conv.0.weight\n",
      "1 torch.Size([32]) --->  layer0.0.conv.1.weight\n",
      "2 torch.Size([32]) --->  layer0.0.conv.1.bias\n",
      "3 torch.Size([32]) --->  layer0.0.conv.1.running_mean\n",
      "4 torch.Size([32]) --->  layer0.0.conv.1.running_var\n",
      "6 torch.Size([32, 32, 1, 1]) --->  layer1.0.block.0.weight\n",
      "7 torch.Size([32]) --->  layer1.0.block.1.weight\n",
      "8 torch.Size([32]) --->  layer1.0.block.1.bias\n",
      "9 torch.Size([32]) --->  layer1.0.block.1.running_mean\n",
      "10 torch.Size([32]) --->  layer1.0.block.1.running_var\n",
      "12 torch.Size([32, 1, 3, 3]) --->  layer1.0.block.3.weight\n",
      "13 torch.Size([32]) --->  layer1.0.block.4.weight\n",
      "14 torch.Size([32]) --->  layer1.0.block.4.bias\n",
      "15 torch.Size([32]) --->  layer1.0.block.4.running_mean\n",
      "16 torch.Size([32]) --->  layer1.0.block.4.running_var\n",
      "18 torch.Size([16, 32, 1, 1]) --->  layer1.0.block.6.weight\n",
      "19 torch.Size([16]) --->  layer1.0.block.7.weight\n",
      "20 torch.Size([16]) --->  layer1.0.block.7.bias\n",
      "21 torch.Size([16]) --->  layer1.0.block.7.running_mean\n",
      "22 torch.Size([16]) --->  layer1.0.block.7.running_var\n",
      "24 torch.Size([96, 16, 1, 1]) --->  layer2.0.block.0.weight\n",
      "25 torch.Size([96]) --->  layer2.0.block.1.weight\n",
      "26 torch.Size([96]) --->  layer2.0.block.1.bias\n",
      "27 torch.Size([96]) --->  layer2.0.block.1.running_mean\n",
      "28 torch.Size([96]) --->  layer2.0.block.1.running_var\n",
      "30 torch.Size([96, 1, 3, 3]) --->  layer2.0.block.3.weight\n",
      "31 torch.Size([96]) --->  layer2.0.block.4.weight\n",
      "32 torch.Size([96]) --->  layer2.0.block.4.bias\n",
      "33 torch.Size([96]) --->  layer2.0.block.4.running_mean\n",
      "34 torch.Size([96]) --->  layer2.0.block.4.running_var\n",
      "36 torch.Size([24, 96, 1, 1]) --->  layer2.0.block.6.weight\n",
      "37 torch.Size([24]) --->  layer2.0.block.7.weight\n",
      "38 torch.Size([24]) --->  layer2.0.block.7.bias\n",
      "39 torch.Size([24]) --->  layer2.0.block.7.running_mean\n",
      "40 torch.Size([24]) --->  layer2.0.block.7.running_var\n",
      "42 torch.Size([144, 24, 1, 1]) --->  layer2.1.block.0.weight\n",
      "43 torch.Size([144]) --->  layer2.1.block.1.weight\n",
      "44 torch.Size([144]) --->  layer2.1.block.1.bias\n",
      "45 torch.Size([144]) --->  layer2.1.block.1.running_mean\n",
      "46 torch.Size([144]) --->  layer2.1.block.1.running_var\n",
      "48 torch.Size([144, 1, 3, 3]) --->  layer2.1.block.3.weight\n",
      "49 torch.Size([144]) --->  layer2.1.block.4.weight\n",
      "50 torch.Size([144]) --->  layer2.1.block.4.bias\n",
      "51 torch.Size([144]) --->  layer2.1.block.4.running_mean\n",
      "52 torch.Size([144]) --->  layer2.1.block.4.running_var\n",
      "54 torch.Size([24, 144, 1, 1]) --->  layer2.1.block.6.weight\n",
      "55 torch.Size([24]) --->  layer2.1.block.7.weight\n",
      "56 torch.Size([24]) --->  layer2.1.block.7.bias\n",
      "57 torch.Size([24]) --->  layer2.1.block.7.running_mean\n",
      "58 torch.Size([24]) --->  layer2.1.block.7.running_var\n",
      "60 torch.Size([144, 24, 1, 1]) --->  layer3.0.block.0.weight\n",
      "61 torch.Size([144]) --->  layer3.0.block.1.weight\n",
      "62 torch.Size([144]) --->  layer3.0.block.1.bias\n",
      "63 torch.Size([144]) --->  layer3.0.block.1.running_mean\n",
      "64 torch.Size([144]) --->  layer3.0.block.1.running_var\n",
      "66 torch.Size([144, 1, 3, 3]) --->  layer3.0.block.3.weight\n",
      "67 torch.Size([144]) --->  layer3.0.block.4.weight\n",
      "68 torch.Size([144]) --->  layer3.0.block.4.bias\n",
      "69 torch.Size([144]) --->  layer3.0.block.4.running_mean\n",
      "70 torch.Size([144]) --->  layer3.0.block.4.running_var\n",
      "72 torch.Size([32, 144, 1, 1]) --->  layer3.0.block.6.weight\n",
      "73 torch.Size([32]) --->  layer3.0.block.7.weight\n",
      "74 torch.Size([32]) --->  layer3.0.block.7.bias\n",
      "75 torch.Size([32]) --->  layer3.0.block.7.running_mean\n",
      "76 torch.Size([32]) --->  layer3.0.block.7.running_var\n",
      "78 torch.Size([192, 32, 1, 1]) --->  layer3.1.block.0.weight\n",
      "79 torch.Size([192]) --->  layer3.1.block.1.weight\n",
      "80 torch.Size([192]) --->  layer3.1.block.1.bias\n",
      "81 torch.Size([192]) --->  layer3.1.block.1.running_mean\n",
      "82 torch.Size([192]) --->  layer3.1.block.1.running_var\n",
      "84 torch.Size([192, 1, 3, 3]) --->  layer3.1.block.3.weight\n",
      "85 torch.Size([192]) --->  layer3.1.block.4.weight\n",
      "86 torch.Size([192]) --->  layer3.1.block.4.bias\n",
      "87 torch.Size([192]) --->  layer3.1.block.4.running_mean\n",
      "88 torch.Size([192]) --->  layer3.1.block.4.running_var\n",
      "90 torch.Size([32, 192, 1, 1]) --->  layer3.1.block.6.weight\n",
      "91 torch.Size([32]) --->  layer3.1.block.7.weight\n",
      "92 torch.Size([32]) --->  layer3.1.block.7.bias\n",
      "93 torch.Size([32]) --->  layer3.1.block.7.running_mean\n",
      "94 torch.Size([32]) --->  layer3.1.block.7.running_var\n",
      "96 torch.Size([192, 32, 1, 1]) --->  layer3.2.block.0.weight\n",
      "97 torch.Size([192]) --->  layer3.2.block.1.weight\n",
      "98 torch.Size([192]) --->  layer3.2.block.1.bias\n",
      "99 torch.Size([192]) --->  layer3.2.block.1.running_mean\n",
      "100 torch.Size([192]) --->  layer3.2.block.1.running_var\n",
      "102 torch.Size([192, 1, 3, 3]) --->  layer3.2.block.3.weight\n",
      "103 torch.Size([192]) --->  layer3.2.block.4.weight\n",
      "104 torch.Size([192]) --->  layer3.2.block.4.bias\n",
      "105 torch.Size([192]) --->  layer3.2.block.4.running_mean\n",
      "106 torch.Size([192]) --->  layer3.2.block.4.running_var\n",
      "108 torch.Size([32, 192, 1, 1]) --->  layer3.2.block.6.weight\n",
      "109 torch.Size([32]) --->  layer3.2.block.7.weight\n",
      "110 torch.Size([32]) --->  layer3.2.block.7.bias\n",
      "111 torch.Size([32]) --->  layer3.2.block.7.running_mean\n",
      "112 torch.Size([32]) --->  layer3.2.block.7.running_var\n",
      "120 torch.Size([192, 32, 1, 1]) --->  layer4.0.block.0.weight\n",
      "121 torch.Size([192]) --->  layer4.0.block.1.weight\n",
      "122 torch.Size([192]) --->  layer4.0.block.1.bias\n",
      "123 torch.Size([192]) --->  layer4.0.block.1.running_mean\n",
      "124 torch.Size([192]) --->  layer4.0.block.1.running_var\n",
      "126 torch.Size([192, 1, 3, 3]) --->  layer4.0.block.3.weight\n",
      "127 torch.Size([192]) --->  layer4.0.block.4.weight\n",
      "128 torch.Size([192]) --->  layer4.0.block.4.bias\n",
      "129 torch.Size([192]) --->  layer4.0.block.4.running_mean\n",
      "130 torch.Size([192]) --->  layer4.0.block.4.running_var\n",
      "132 torch.Size([64, 192, 1, 1]) --->  layer4.0.block.6.weight\n",
      "133 torch.Size([64]) --->  layer4.0.block.7.weight\n",
      "134 torch.Size([64]) --->  layer4.0.block.7.bias\n",
      "135 torch.Size([64]) --->  layer4.0.block.7.running_mean\n",
      "136 torch.Size([64]) --->  layer4.0.block.7.running_var\n",
      "138 torch.Size([384, 64, 1, 1]) --->  layer4.1.block.0.weight\n",
      "139 torch.Size([384]) --->  layer4.1.block.1.weight\n",
      "140 torch.Size([384]) --->  layer4.1.block.1.bias\n",
      "141 torch.Size([384]) --->  layer4.1.block.1.running_mean\n",
      "142 torch.Size([384]) --->  layer4.1.block.1.running_var\n",
      "144 torch.Size([384, 1, 3, 3]) --->  layer4.1.block.3.weight\n",
      "145 torch.Size([384]) --->  layer4.1.block.4.weight\n",
      "146 torch.Size([384]) --->  layer4.1.block.4.bias\n",
      "147 torch.Size([384]) --->  layer4.1.block.4.running_mean\n",
      "148 torch.Size([384]) --->  layer4.1.block.4.running_var\n",
      "150 torch.Size([64, 384, 1, 1]) --->  layer4.1.block.6.weight\n",
      "151 torch.Size([64]) --->  layer4.1.block.7.weight\n",
      "152 torch.Size([64]) --->  layer4.1.block.7.bias\n",
      "153 torch.Size([64]) --->  layer4.1.block.7.running_mean\n",
      "154 torch.Size([64]) --->  layer4.1.block.7.running_var\n",
      "156 torch.Size([384, 64, 1, 1]) --->  layer4.2.block.0.weight\n",
      "157 torch.Size([384]) --->  layer4.2.block.1.weight\n",
      "158 torch.Size([384]) --->  layer4.2.block.1.bias\n",
      "159 torch.Size([384]) --->  layer4.2.block.1.running_mean\n",
      "160 torch.Size([384]) --->  layer4.2.block.1.running_var\n",
      "162 torch.Size([384, 1, 3, 3]) --->  layer4.2.block.3.weight\n",
      "163 torch.Size([384]) --->  layer4.2.block.4.weight\n",
      "164 torch.Size([384]) --->  layer4.2.block.4.bias\n",
      "165 torch.Size([384]) --->  layer4.2.block.4.running_mean\n",
      "166 torch.Size([384]) --->  layer4.2.block.4.running_var\n",
      "168 torch.Size([64, 384, 1, 1]) --->  layer4.2.block.6.weight\n",
      "169 torch.Size([64]) --->  layer4.2.block.7.weight\n",
      "170 torch.Size([64]) --->  layer4.2.block.7.bias\n",
      "171 torch.Size([64]) --->  layer4.2.block.7.running_mean\n",
      "172 torch.Size([64]) --->  layer4.2.block.7.running_var\n",
      "174 torch.Size([384, 64, 1, 1]) --->  layer4.3.block.0.weight\n",
      "175 torch.Size([384]) --->  layer4.3.block.1.weight\n",
      "176 torch.Size([384]) --->  layer4.3.block.1.bias\n",
      "177 torch.Size([384]) --->  layer4.3.block.1.running_mean\n",
      "178 torch.Size([384]) --->  layer4.3.block.1.running_var\n",
      "180 torch.Size([384, 1, 3, 3]) --->  layer4.3.block.3.weight\n",
      "181 torch.Size([384]) --->  layer4.3.block.4.weight\n",
      "182 torch.Size([384]) --->  layer4.3.block.4.bias\n",
      "183 torch.Size([384]) --->  layer4.3.block.4.running_mean\n",
      "184 torch.Size([384]) --->  layer4.3.block.4.running_var\n",
      "186 torch.Size([64, 384, 1, 1]) --->  layer4.3.block.6.weight\n",
      "187 torch.Size([64]) --->  layer4.3.block.7.weight\n",
      "188 torch.Size([64]) --->  layer4.3.block.7.bias\n",
      "189 torch.Size([64]) --->  layer4.3.block.7.running_mean\n",
      "190 torch.Size([64]) --->  layer4.3.block.7.running_var\n",
      "192 torch.Size([384, 64, 1, 1]) --->  layer5.0.block.0.weight\n",
      "193 torch.Size([384]) --->  layer5.0.block.1.weight\n",
      "194 torch.Size([384]) --->  layer5.0.block.1.bias\n",
      "195 torch.Size([384]) --->  layer5.0.block.1.running_mean\n",
      "196 torch.Size([384]) --->  layer5.0.block.1.running_var\n",
      "198 torch.Size([384, 1, 3, 3]) --->  layer5.0.block.3.weight\n",
      "199 torch.Size([384]) --->  layer5.0.block.4.weight\n",
      "200 torch.Size([384]) --->  layer5.0.block.4.bias\n",
      "201 torch.Size([384]) --->  layer5.0.block.4.running_mean\n",
      "202 torch.Size([384]) --->  layer5.0.block.4.running_var\n",
      "204 torch.Size([96, 384, 1, 1]) --->  layer5.0.block.6.weight\n",
      "205 torch.Size([96]) --->  layer5.0.block.7.weight\n",
      "206 torch.Size([96]) --->  layer5.0.block.7.bias\n",
      "207 torch.Size([96]) --->  layer5.0.block.7.running_mean\n",
      "208 torch.Size([96]) --->  layer5.0.block.7.running_var\n",
      "210 torch.Size([576, 96, 1, 1]) --->  layer5.1.block.0.weight\n",
      "211 torch.Size([576]) --->  layer5.1.block.1.weight\n",
      "212 torch.Size([576]) --->  layer5.1.block.1.bias\n",
      "213 torch.Size([576]) --->  layer5.1.block.1.running_mean\n",
      "214 torch.Size([576]) --->  layer5.1.block.1.running_var\n",
      "216 torch.Size([576, 1, 3, 3]) --->  layer5.1.block.3.weight\n",
      "217 torch.Size([576]) --->  layer5.1.block.4.weight\n",
      "218 torch.Size([576]) --->  layer5.1.block.4.bias\n",
      "219 torch.Size([576]) --->  layer5.1.block.4.running_mean\n",
      "220 torch.Size([576]) --->  layer5.1.block.4.running_var\n",
      "222 torch.Size([96, 576, 1, 1]) --->  layer5.1.block.6.weight\n",
      "223 torch.Size([96]) --->  layer5.1.block.7.weight\n",
      "224 torch.Size([96]) --->  layer5.1.block.7.bias\n",
      "225 torch.Size([96]) --->  layer5.1.block.7.running_mean\n",
      "226 torch.Size([96]) --->  layer5.1.block.7.running_var\n",
      "228 torch.Size([576, 96, 1, 1]) --->  layer5.2.block.0.weight\n",
      "229 torch.Size([576]) --->  layer5.2.block.1.weight\n",
      "230 torch.Size([576]) --->  layer5.2.block.1.bias\n",
      "231 torch.Size([576]) --->  layer5.2.block.1.running_mean\n",
      "232 torch.Size([576]) --->  layer5.2.block.1.running_var\n",
      "234 torch.Size([576, 1, 3, 3]) --->  layer5.2.block.3.weight\n",
      "235 torch.Size([576]) --->  layer5.2.block.4.weight\n",
      "236 torch.Size([576]) --->  layer5.2.block.4.bias\n",
      "237 torch.Size([576]) --->  layer5.2.block.4.running_mean\n",
      "238 torch.Size([576]) --->  layer5.2.block.4.running_var\n",
      "240 torch.Size([96, 576, 1, 1]) --->  layer5.2.block.6.weight\n",
      "241 torch.Size([96]) --->  layer5.2.block.7.weight\n",
      "242 torch.Size([96]) --->  layer5.2.block.7.bias\n",
      "243 torch.Size([96]) --->  layer5.2.block.7.running_mean\n",
      "244 torch.Size([96]) --->  layer5.2.block.7.running_var\n",
      "252 torch.Size([576, 96, 1, 1]) --->  layer6.0.block.0.weight\n",
      "253 torch.Size([576]) --->  layer6.0.block.1.weight\n",
      "254 torch.Size([576]) --->  layer6.0.block.1.bias\n",
      "255 torch.Size([576]) --->  layer6.0.block.1.running_mean\n",
      "256 torch.Size([576]) --->  layer6.0.block.1.running_var\n",
      "258 torch.Size([576, 1, 3, 3]) --->  layer6.0.block.3.weight\n",
      "259 torch.Size([576]) --->  layer6.0.block.4.weight\n",
      "260 torch.Size([576]) --->  layer6.0.block.4.bias\n",
      "261 torch.Size([576]) --->  layer6.0.block.4.running_mean\n",
      "262 torch.Size([576]) --->  layer6.0.block.4.running_var\n",
      "264 torch.Size([160, 576, 1, 1]) --->  layer6.0.block.6.weight\n",
      "265 torch.Size([160]) --->  layer6.0.block.7.weight\n",
      "266 torch.Size([160]) --->  layer6.0.block.7.bias\n",
      "267 torch.Size([160]) --->  layer6.0.block.7.running_mean\n",
      "268 torch.Size([160]) --->  layer6.0.block.7.running_var\n",
      "270 torch.Size([960, 160, 1, 1]) --->  layer6.1.block.0.weight\n",
      "271 torch.Size([960]) --->  layer6.1.block.1.weight\n",
      "272 torch.Size([960]) --->  layer6.1.block.1.bias\n",
      "273 torch.Size([960]) --->  layer6.1.block.1.running_mean\n",
      "274 torch.Size([960]) --->  layer6.1.block.1.running_var\n",
      "276 torch.Size([960, 1, 3, 3]) --->  layer6.1.block.3.weight\n",
      "277 torch.Size([960]) --->  layer6.1.block.4.weight\n",
      "278 torch.Size([960]) --->  layer6.1.block.4.bias\n",
      "279 torch.Size([960]) --->  layer6.1.block.4.running_mean\n",
      "280 torch.Size([960]) --->  layer6.1.block.4.running_var\n",
      "282 torch.Size([160, 960, 1, 1]) --->  layer6.1.block.6.weight\n",
      "283 torch.Size([160]) --->  layer6.1.block.7.weight\n",
      "284 torch.Size([160]) --->  layer6.1.block.7.bias\n",
      "285 torch.Size([160]) --->  layer6.1.block.7.running_mean\n",
      "286 torch.Size([160]) --->  layer6.1.block.7.running_var\n",
      "288 torch.Size([960, 160, 1, 1]) --->  layer6.2.block.0.weight\n",
      "289 torch.Size([960]) --->  layer6.2.block.1.weight\n",
      "290 torch.Size([960]) --->  layer6.2.block.1.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291 torch.Size([960]) --->  layer6.2.block.1.running_mean\n",
      "292 torch.Size([960]) --->  layer6.2.block.1.running_var\n",
      "294 torch.Size([960, 1, 3, 3]) --->  layer6.2.block.3.weight\n",
      "295 torch.Size([960]) --->  layer6.2.block.4.weight\n",
      "296 torch.Size([960]) --->  layer6.2.block.4.bias\n",
      "297 torch.Size([960]) --->  layer6.2.block.4.running_mean\n",
      "298 torch.Size([960]) --->  layer6.2.block.4.running_var\n",
      "300 torch.Size([160, 960, 1, 1]) --->  layer6.2.block.6.weight\n",
      "301 torch.Size([160]) --->  layer6.2.block.7.weight\n",
      "302 torch.Size([160]) --->  layer6.2.block.7.bias\n",
      "303 torch.Size([160]) --->  layer6.2.block.7.running_mean\n",
      "304 torch.Size([160]) --->  layer6.2.block.7.running_var\n",
      "306 torch.Size([960, 160, 1, 1]) --->  layer7.0.block.0.weight\n",
      "307 torch.Size([960]) --->  layer7.0.block.1.weight\n",
      "308 torch.Size([960]) --->  layer7.0.block.1.bias\n",
      "309 torch.Size([960]) --->  layer7.0.block.1.running_mean\n",
      "310 torch.Size([960]) --->  layer7.0.block.1.running_var\n",
      "312 torch.Size([960, 1, 3, 3]) --->  layer7.0.block.3.weight\n",
      "313 torch.Size([960]) --->  layer7.0.block.4.weight\n",
      "314 torch.Size([960]) --->  layer7.0.block.4.bias\n",
      "315 torch.Size([960]) --->  layer7.0.block.4.running_mean\n",
      "316 torch.Size([960]) --->  layer7.0.block.4.running_var\n",
      "318 torch.Size([320, 960, 1, 1]) --->  layer7.0.block.6.weight\n",
      "319 torch.Size([320]) --->  layer7.0.block.7.weight\n",
      "320 torch.Size([320]) --->  layer7.0.block.7.bias\n",
      "321 torch.Size([320]) --->  layer7.0.block.7.running_mean\n",
      "322 torch.Size([320]) --->  layer7.0.block.7.running_var\n",
      "324 torch.Size([1280, 320, 1, 1]) --->  layer8.0.conv.0.weight\n",
      "325 torch.Size([1280]) --->  layer8.0.conv.1.weight\n",
      "326 torch.Size([1280]) --->  layer8.0.conv.1.bias\n",
      "327 torch.Size([1280]) --->  layer8.0.conv.1.running_mean\n",
      "328 torch.Size([1280]) --->  layer8.0.conv.1.running_var\n",
      "\n",
      "Number of weights:  265\n"
     ]
    }
   ],
   "source": [
    "_model_keys = []\n",
    "_model_key_ids = []\n",
    "for i, w in enumerate(model_weights):\n",
    "    if i not in ignore_indices:\n",
    "        _model_keys.append(model_keys[i])\n",
    "        _model_key_ids.append(i)\n",
    "        print(i, w.size(), '---> ', model_keys[i])\n",
    "\n",
    "print()\n",
    "print('Number of weights: ', len(_model_keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([32, 3, 3, 3]) --->  module.conv1.weight\n",
      "1 torch.Size([32]) --->  module.bn1.weight\n",
      "2 torch.Size([32]) --->  module.bn1.bias\n",
      "3 torch.Size([32]) --->  module.bn1.running_mean\n",
      "4 torch.Size([32]) --->  module.bn1.running_var\n",
      "5 torch.Size([32, 32, 1, 1]) --->  module.bottlenecks.Bottlenecks_0.LinearBottleneck0_0.conv1.weight\n",
      "6 torch.Size([32]) --->  module.bottlenecks.Bottlenecks_0.LinearBottleneck0_0.bn1.weight\n",
      "7 torch.Size([32]) --->  module.bottlenecks.Bottlenecks_0.LinearBottleneck0_0.bn1.bias\n",
      "8 torch.Size([32]) --->  module.bottlenecks.Bottlenecks_0.LinearBottleneck0_0.bn1.running_mean\n",
      "9 torch.Size([32]) --->  module.bottlenecks.Bottlenecks_0.LinearBottleneck0_0.bn1.running_var\n",
      "10 torch.Size([32, 1, 3, 3]) --->  module.bottlenecks.Bottlenecks_0.LinearBottleneck0_0.conv2.weight\n",
      "11 torch.Size([32]) --->  module.bottlenecks.Bottlenecks_0.LinearBottleneck0_0.bn2.weight\n",
      "12 torch.Size([32]) --->  module.bottlenecks.Bottlenecks_0.LinearBottleneck0_0.bn2.bias\n",
      "13 torch.Size([32]) --->  module.bottlenecks.Bottlenecks_0.LinearBottleneck0_0.bn2.running_mean\n",
      "14 torch.Size([32]) --->  module.bottlenecks.Bottlenecks_0.LinearBottleneck0_0.bn2.running_var\n",
      "15 torch.Size([16, 32, 1, 1]) --->  module.bottlenecks.Bottlenecks_0.LinearBottleneck0_0.conv3.weight\n",
      "16 torch.Size([16]) --->  module.bottlenecks.Bottlenecks_0.LinearBottleneck0_0.bn3.weight\n",
      "17 torch.Size([16]) --->  module.bottlenecks.Bottlenecks_0.LinearBottleneck0_0.bn3.bias\n",
      "18 torch.Size([16]) --->  module.bottlenecks.Bottlenecks_0.LinearBottleneck0_0.bn3.running_mean\n",
      "19 torch.Size([16]) --->  module.bottlenecks.Bottlenecks_0.LinearBottleneck0_0.bn3.running_var\n",
      "20 torch.Size([96, 16, 1, 1]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_0.conv1.weight\n",
      "21 torch.Size([96]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_0.bn1.weight\n",
      "22 torch.Size([96]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_0.bn1.bias\n",
      "23 torch.Size([96]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_0.bn1.running_mean\n",
      "24 torch.Size([96]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_0.bn1.running_var\n",
      "25 torch.Size([96, 1, 3, 3]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_0.conv2.weight\n",
      "26 torch.Size([96]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_0.bn2.weight\n",
      "27 torch.Size([96]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_0.bn2.bias\n",
      "28 torch.Size([96]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_0.bn2.running_mean\n",
      "29 torch.Size([96]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_0.bn2.running_var\n",
      "30 torch.Size([24, 96, 1, 1]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_0.conv3.weight\n",
      "31 torch.Size([24]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_0.bn3.weight\n",
      "32 torch.Size([24]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_0.bn3.bias\n",
      "33 torch.Size([24]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_0.bn3.running_mean\n",
      "34 torch.Size([24]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_0.bn3.running_var\n",
      "35 torch.Size([144, 24, 1, 1]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_1.conv1.weight\n",
      "36 torch.Size([144]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_1.bn1.weight\n",
      "37 torch.Size([144]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_1.bn1.bias\n",
      "38 torch.Size([144]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_1.bn1.running_mean\n",
      "39 torch.Size([144]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_1.bn1.running_var\n",
      "40 torch.Size([144, 1, 3, 3]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_1.conv2.weight\n",
      "41 torch.Size([144]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_1.bn2.weight\n",
      "42 torch.Size([144]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_1.bn2.bias\n",
      "43 torch.Size([144]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_1.bn2.running_mean\n",
      "44 torch.Size([144]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_1.bn2.running_var\n",
      "45 torch.Size([24, 144, 1, 1]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_1.conv3.weight\n",
      "46 torch.Size([24]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_1.bn3.weight\n",
      "47 torch.Size([24]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_1.bn3.bias\n",
      "48 torch.Size([24]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_1.bn3.running_mean\n",
      "49 torch.Size([24]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_1.bn3.running_var\n",
      "50 torch.Size([144, 24, 1, 1]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_0.conv1.weight\n",
      "51 torch.Size([144]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_0.bn1.weight\n",
      "52 torch.Size([144]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_0.bn1.bias\n",
      "53 torch.Size([144]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_0.bn1.running_mean\n",
      "54 torch.Size([144]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_0.bn1.running_var\n",
      "55 torch.Size([144, 1, 3, 3]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_0.conv2.weight\n",
      "56 torch.Size([144]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_0.bn2.weight\n",
      "57 torch.Size([144]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_0.bn2.bias\n",
      "58 torch.Size([144]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_0.bn2.running_mean\n",
      "59 torch.Size([144]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_0.bn2.running_var\n",
      "60 torch.Size([32, 144, 1, 1]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_0.conv3.weight\n",
      "61 torch.Size([32]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_0.bn3.weight\n",
      "62 torch.Size([32]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_0.bn3.bias\n",
      "63 torch.Size([32]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_0.bn3.running_mean\n",
      "64 torch.Size([32]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_0.bn3.running_var\n",
      "65 torch.Size([192, 32, 1, 1]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_1.conv1.weight\n",
      "66 torch.Size([192]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_1.bn1.weight\n",
      "67 torch.Size([192]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_1.bn1.bias\n",
      "68 torch.Size([192]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_1.bn1.running_mean\n",
      "69 torch.Size([192]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_1.bn1.running_var\n",
      "70 torch.Size([192, 1, 3, 3]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_1.conv2.weight\n",
      "71 torch.Size([192]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_1.bn2.weight\n",
      "72 torch.Size([192]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_1.bn2.bias\n",
      "73 torch.Size([192]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_1.bn2.running_mean\n",
      "74 torch.Size([192]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_1.bn2.running_var\n",
      "75 torch.Size([32, 192, 1, 1]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_1.conv3.weight\n",
      "76 torch.Size([32]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_1.bn3.weight\n",
      "77 torch.Size([32]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_1.bn3.bias\n",
      "78 torch.Size([32]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_1.bn3.running_mean\n",
      "79 torch.Size([32]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_1.bn3.running_var\n",
      "80 torch.Size([192, 32, 1, 1]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_2.conv1.weight\n",
      "81 torch.Size([192]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_2.bn1.weight\n",
      "82 torch.Size([192]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_2.bn1.bias\n",
      "83 torch.Size([192]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_2.bn1.running_mean\n",
      "84 torch.Size([192]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_2.bn1.running_var\n",
      "85 torch.Size([192, 1, 3, 3]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_2.conv2.weight\n",
      "86 torch.Size([192]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_2.bn2.weight\n",
      "87 torch.Size([192]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_2.bn2.bias\n",
      "88 torch.Size([192]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_2.bn2.running_mean\n",
      "89 torch.Size([192]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_2.bn2.running_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 torch.Size([32, 192, 1, 1]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_2.conv3.weight\n",
      "91 torch.Size([32]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_2.bn3.weight\n",
      "92 torch.Size([32]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_2.bn3.bias\n",
      "93 torch.Size([32]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_2.bn3.running_mean\n",
      "94 torch.Size([32]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_2.bn3.running_var\n",
      "95 torch.Size([192, 32, 1, 1]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_0.conv1.weight\n",
      "96 torch.Size([192]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_0.bn1.weight\n",
      "97 torch.Size([192]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_0.bn1.bias\n",
      "98 torch.Size([192]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_0.bn1.running_mean\n",
      "99 torch.Size([192]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_0.bn1.running_var\n",
      "100 torch.Size([192, 1, 3, 3]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_0.conv2.weight\n",
      "101 torch.Size([192]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_0.bn2.weight\n",
      "102 torch.Size([192]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_0.bn2.bias\n",
      "103 torch.Size([192]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_0.bn2.running_mean\n",
      "104 torch.Size([192]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_0.bn2.running_var\n",
      "105 torch.Size([64, 192, 1, 1]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_0.conv3.weight\n",
      "106 torch.Size([64]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_0.bn3.weight\n",
      "107 torch.Size([64]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_0.bn3.bias\n",
      "108 torch.Size([64]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_0.bn3.running_mean\n",
      "109 torch.Size([64]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_0.bn3.running_var\n",
      "110 torch.Size([384, 64, 1, 1]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_1.conv1.weight\n",
      "111 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_1.bn1.weight\n",
      "112 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_1.bn1.bias\n",
      "113 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_1.bn1.running_mean\n",
      "114 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_1.bn1.running_var\n",
      "115 torch.Size([384, 1, 3, 3]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_1.conv2.weight\n",
      "116 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_1.bn2.weight\n",
      "117 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_1.bn2.bias\n",
      "118 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_1.bn2.running_mean\n",
      "119 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_1.bn2.running_var\n",
      "120 torch.Size([64, 384, 1, 1]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_1.conv3.weight\n",
      "121 torch.Size([64]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_1.bn3.weight\n",
      "122 torch.Size([64]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_1.bn3.bias\n",
      "123 torch.Size([64]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_1.bn3.running_mean\n",
      "124 torch.Size([64]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_1.bn3.running_var\n",
      "125 torch.Size([384, 64, 1, 1]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_2.conv1.weight\n",
      "126 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_2.bn1.weight\n",
      "127 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_2.bn1.bias\n",
      "128 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_2.bn1.running_mean\n",
      "129 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_2.bn1.running_var\n",
      "130 torch.Size([384, 1, 3, 3]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_2.conv2.weight\n",
      "131 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_2.bn2.weight\n",
      "132 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_2.bn2.bias\n",
      "133 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_2.bn2.running_mean\n",
      "134 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_2.bn2.running_var\n",
      "135 torch.Size([64, 384, 1, 1]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_2.conv3.weight\n",
      "136 torch.Size([64]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_2.bn3.weight\n",
      "137 torch.Size([64]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_2.bn3.bias\n",
      "138 torch.Size([64]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_2.bn3.running_mean\n",
      "139 torch.Size([64]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_2.bn3.running_var\n",
      "140 torch.Size([384, 64, 1, 1]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_3.conv1.weight\n",
      "141 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_3.bn1.weight\n",
      "142 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_3.bn1.bias\n",
      "143 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_3.bn1.running_mean\n",
      "144 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_3.bn1.running_var\n",
      "145 torch.Size([384, 1, 3, 3]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_3.conv2.weight\n",
      "146 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_3.bn2.weight\n",
      "147 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_3.bn2.bias\n",
      "148 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_3.bn2.running_mean\n",
      "149 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_3.bn2.running_var\n",
      "150 torch.Size([64, 384, 1, 1]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_3.conv3.weight\n",
      "151 torch.Size([64]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_3.bn3.weight\n",
      "152 torch.Size([64]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_3.bn3.bias\n",
      "153 torch.Size([64]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_3.bn3.running_mean\n",
      "154 torch.Size([64]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_3.bn3.running_var\n",
      "155 torch.Size([384, 64, 1, 1]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_0.conv1.weight\n",
      "156 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_0.bn1.weight\n",
      "157 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_0.bn1.bias\n",
      "158 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_0.bn1.running_mean\n",
      "159 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_0.bn1.running_var\n",
      "160 torch.Size([384, 1, 3, 3]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_0.conv2.weight\n",
      "161 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_0.bn2.weight\n",
      "162 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_0.bn2.bias\n",
      "163 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_0.bn2.running_mean\n",
      "164 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_0.bn2.running_var\n",
      "165 torch.Size([96, 384, 1, 1]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_0.conv3.weight\n",
      "166 torch.Size([96]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_0.bn3.weight\n",
      "167 torch.Size([96]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_0.bn3.bias\n",
      "168 torch.Size([96]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_0.bn3.running_mean\n",
      "169 torch.Size([96]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_0.bn3.running_var\n",
      "170 torch.Size([576, 96, 1, 1]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_1.conv1.weight\n",
      "171 torch.Size([576]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_1.bn1.weight\n",
      "172 torch.Size([576]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_1.bn1.bias\n",
      "173 torch.Size([576]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_1.bn1.running_mean\n",
      "174 torch.Size([576]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_1.bn1.running_var\n",
      "175 torch.Size([576, 1, 3, 3]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_1.conv2.weight\n",
      "176 torch.Size([576]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_1.bn2.weight\n",
      "177 torch.Size([576]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_1.bn2.bias\n",
      "178 torch.Size([576]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_1.bn2.running_mean\n",
      "179 torch.Size([576]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_1.bn2.running_var\n",
      "180 torch.Size([96, 576, 1, 1]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_1.conv3.weight\n",
      "181 torch.Size([96]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_1.bn3.weight\n",
      "182 torch.Size([96]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_1.bn3.bias\n",
      "183 torch.Size([96]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_1.bn3.running_mean\n",
      "184 torch.Size([96]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_1.bn3.running_var\n",
      "185 torch.Size([576, 96, 1, 1]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_2.conv1.weight\n",
      "186 torch.Size([576]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_2.bn1.weight\n",
      "187 torch.Size([576]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_2.bn1.bias\n",
      "188 torch.Size([576]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_2.bn1.running_mean\n",
      "189 torch.Size([576]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_2.bn1.running_var\n",
      "190 torch.Size([576, 1, 3, 3]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_2.conv2.weight\n",
      "191 torch.Size([576]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_2.bn2.weight\n",
      "192 torch.Size([576]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_2.bn2.bias\n",
      "193 torch.Size([576]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_2.bn2.running_mean\n",
      "194 torch.Size([576]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_2.bn2.running_var\n",
      "195 torch.Size([96, 576, 1, 1]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_2.conv3.weight\n",
      "196 torch.Size([96]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_2.bn3.weight\n",
      "197 torch.Size([96]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_2.bn3.bias\n",
      "198 torch.Size([96]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_2.bn3.running_mean\n",
      "199 torch.Size([96]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_2.bn3.running_var\n",
      "200 torch.Size([576, 96, 1, 1]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_0.conv1.weight\n",
      "201 torch.Size([576]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_0.bn1.weight\n",
      "202 torch.Size([576]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_0.bn1.bias\n",
      "203 torch.Size([576]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_0.bn1.running_mean\n",
      "204 torch.Size([576]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_0.bn1.running_var\n",
      "205 torch.Size([576, 1, 3, 3]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_0.conv2.weight\n",
      "206 torch.Size([576]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_0.bn2.weight\n",
      "207 torch.Size([576]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_0.bn2.bias\n",
      "208 torch.Size([576]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_0.bn2.running_mean\n",
      "209 torch.Size([576]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_0.bn2.running_var\n",
      "210 torch.Size([160, 576, 1, 1]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_0.conv3.weight\n",
      "211 torch.Size([160]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_0.bn3.weight\n",
      "212 torch.Size([160]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_0.bn3.bias\n",
      "213 torch.Size([160]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_0.bn3.running_mean\n",
      "214 torch.Size([160]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_0.bn3.running_var\n",
      "215 torch.Size([960, 160, 1, 1]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_1.conv1.weight\n",
      "216 torch.Size([960]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_1.bn1.weight\n",
      "217 torch.Size([960]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_1.bn1.bias\n",
      "218 torch.Size([960]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_1.bn1.running_mean\n",
      "219 torch.Size([960]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_1.bn1.running_var\n",
      "220 torch.Size([960, 1, 3, 3]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_1.conv2.weight\n",
      "221 torch.Size([960]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_1.bn2.weight\n",
      "222 torch.Size([960]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_1.bn2.bias\n",
      "223 torch.Size([960]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_1.bn2.running_mean\n",
      "224 torch.Size([960]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_1.bn2.running_var\n",
      "225 torch.Size([160, 960, 1, 1]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_1.conv3.weight\n",
      "226 torch.Size([160]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_1.bn3.weight\n",
      "227 torch.Size([160]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_1.bn3.bias\n",
      "228 torch.Size([160]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_1.bn3.running_mean\n",
      "229 torch.Size([160]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_1.bn3.running_var\n",
      "230 torch.Size([960, 160, 1, 1]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_2.conv1.weight\n",
      "231 torch.Size([960]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_2.bn1.weight\n",
      "232 torch.Size([960]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_2.bn1.bias\n",
      "233 torch.Size([960]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_2.bn1.running_mean\n",
      "234 torch.Size([960]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_2.bn1.running_var\n",
      "235 torch.Size([960, 1, 3, 3]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_2.conv2.weight\n",
      "236 torch.Size([960]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_2.bn2.weight\n",
      "237 torch.Size([960]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_2.bn2.bias\n",
      "238 torch.Size([960]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_2.bn2.running_mean\n",
      "239 torch.Size([960]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_2.bn2.running_var\n",
      "240 torch.Size([160, 960, 1, 1]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_2.conv3.weight\n",
      "241 torch.Size([160]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_2.bn3.weight\n",
      "242 torch.Size([160]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_2.bn3.bias\n",
      "243 torch.Size([160]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_2.bn3.running_mean\n",
      "244 torch.Size([160]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_2.bn3.running_var\n",
      "245 torch.Size([960, 160, 1, 1]) --->  module.bottlenecks.Bottlenecks_6.LinearBottleneck6_0.conv1.weight\n",
      "246 torch.Size([960]) --->  module.bottlenecks.Bottlenecks_6.LinearBottleneck6_0.bn1.weight\n",
      "247 torch.Size([960]) --->  module.bottlenecks.Bottlenecks_6.LinearBottleneck6_0.bn1.bias\n",
      "248 torch.Size([960]) --->  module.bottlenecks.Bottlenecks_6.LinearBottleneck6_0.bn1.running_mean\n",
      "249 torch.Size([960]) --->  module.bottlenecks.Bottlenecks_6.LinearBottleneck6_0.bn1.running_var\n",
      "250 torch.Size([960, 1, 3, 3]) --->  module.bottlenecks.Bottlenecks_6.LinearBottleneck6_0.conv2.weight\n",
      "251 torch.Size([960]) --->  module.bottlenecks.Bottlenecks_6.LinearBottleneck6_0.bn2.weight\n",
      "252 torch.Size([960]) --->  module.bottlenecks.Bottlenecks_6.LinearBottleneck6_0.bn2.bias\n",
      "253 torch.Size([960]) --->  module.bottlenecks.Bottlenecks_6.LinearBottleneck6_0.bn2.running_mean\n",
      "254 torch.Size([960]) --->  module.bottlenecks.Bottlenecks_6.LinearBottleneck6_0.bn2.running_var\n",
      "255 torch.Size([320, 960, 1, 1]) --->  module.bottlenecks.Bottlenecks_6.LinearBottleneck6_0.conv3.weight\n",
      "256 torch.Size([320]) --->  module.bottlenecks.Bottlenecks_6.LinearBottleneck6_0.bn3.weight\n",
      "257 torch.Size([320]) --->  module.bottlenecks.Bottlenecks_6.LinearBottleneck6_0.bn3.bias\n",
      "258 torch.Size([320]) --->  module.bottlenecks.Bottlenecks_6.LinearBottleneck6_0.bn3.running_mean\n",
      "259 torch.Size([320]) --->  module.bottlenecks.Bottlenecks_6.LinearBottleneck6_0.bn3.running_var\n",
      "260 torch.Size([1280, 320, 1, 1]) --->  module.conv_last.weight\n",
      "261 torch.Size([1280]) --->  module.bn_last.weight\n",
      "262 torch.Size([1280]) --->  module.bn_last.bias\n",
      "263 torch.Size([1280]) --->  module.bn_last.running_mean\n",
      "264 torch.Size([1280]) --->  module.bn_last.running_var\n",
      "\n",
      "Number of weights:  265\n"
     ]
    }
   ],
   "source": [
    "_trained_keys = []\n",
    "_trained_key_ids = []\n",
    "for i, w in enumerate(trained_weights[:-2]):\n",
    "    _trained_keys.append(trained_keys[i])\n",
    "    _trained_key_ids.append(i)\n",
    "    print(i, w.size(), '---> ', trained_keys[i])\n",
    "    \n",
    "print()\n",
    "print('Number of weights: ', len(_trained_keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_key_map = dict(zip(_trained_keys, _model_keys))\n",
    "trained_key_ids_map = dict(zip(_trained_key_ids, _model_key_ids))\n",
    "\n",
    "for train_key_id, model_key_id in trained_key_ids_map.items():\n",
    "    assert trained_weights[train_key_id].shape == model_weights[model_key_id].shape\n",
    "    \n",
    "for train_key, model_key in trained_key_map.items():\n",
    "    assert trained_state_dict['state_dict'][train_key].shape == model.state_dict()[model_key].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Weights and Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model pre-trained on ImageNet weights\n",
    "pre_trained_state = torch.load('./MobileNetV2.pth.tar')['state_dict']\n",
    "\n",
    "# Modified MobileNet\n",
    "mobile_net = MobileNetV2(params=config)\n",
    "mobile_net_state = mobile_net.state_dict()\n",
    "\n",
    "for train_key, model_key in trained_key_map.items():\n",
    "    mobile_net_state[model_key] = pre_trained_state[train_key]\n",
    "    \n",
    "mobile_net.load_state_dict(mobile_net_state)\n",
    "torch.save(mobile_net.state_dict(), 'MobileNetV2-Pretrained-Weights.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0176,  0.0243, -0.0063],\n",
      "         [ 0.0567, -0.8243, -0.0080],\n",
      "         [-0.1055,  0.6830,  0.0980]]], device='cuda:1')\n",
      "\n",
      "tensor([[[ 0.0176,  0.0243, -0.0063],\n",
      "         [ 0.0567, -0.8243, -0.0080],\n",
      "         [-0.1055,  0.6830,  0.0980]]], device='cuda:1')\n",
      "\n",
      "tensor([[[ 0.0176,  0.0243, -0.0063],\n",
      "         [ 0.0567, -0.8243, -0.0080],\n",
      "         [-0.1055,  0.6830,  0.0980]]])\n"
     ]
    }
   ],
   "source": [
    "print(pre_trained_state['module.bottlenecks.Bottlenecks_0.LinearBottleneck0_0.conv2.weight'][1,...])\n",
    "print()\n",
    "print(mobile_net_state['layer1.0.block.3.weight'][1, ...])\n",
    "print()\n",
    "print(mobile_net.state_dict()['layer1.0.block.3.weight'][1, ...])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if Weights load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0176,  0.0243, -0.0063],\n",
      "         [ 0.0567, -0.8243, -0.0080],\n",
      "         [-0.1055,  0.6830,  0.0980]]])\n"
     ]
    }
   ],
   "source": [
    "net = MobileNetV2(params=config)\n",
    "net_state = torch.load('./MobileNetV2-Pretrained-Weights.pth.tar')\n",
    "print(net_state['layer1.0.block.3.weight'][1, ...])\n",
    "net.load_state_dict(net_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
