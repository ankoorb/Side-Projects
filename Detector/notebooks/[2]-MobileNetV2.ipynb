{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MobileNetV2/YOLOv3 parameters \n",
    "\n",
    "class MobileNetParams():\n",
    "    \"\"\"\n",
    "    Parameters for MobileNetV2\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # Conv and Inverted Residual Parameters: Table-2 (https://arxiv.org/pdf/1801.04381.pdf)\n",
    "        self.t = [1, 1, 6, 6, 6, 6, 6, 6]  # t: expansion factor\n",
    "        self.c = [32, 16, 24, 32, 64, 96, 160, 320]  # c: Output channels\n",
    "        self.n = [1, 1, 2, 3, 4, 3, 3, 1]  # n: Number of times layer is repeated\n",
    "        self.s = [2, 1, 2, 2, 2, 1, 2, 1]  # s: Stride\n",
    "        \n",
    "        # Width multiplier: Controls the width of the network\n",
    "        self.alpha = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers\n",
    "\n",
    "## References\n",
    "# 1. https://github.com/keras-team/keras-applications/blob/master/keras_applications/mobilenet_v2.py\n",
    "# 2. https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n",
    "# 3. https://github.com/tonylins/pytorch-mobilenet-v2/blob/master/MobileNetV2.py\n",
    "\n",
    "def _make_divisible(v, divisor, min_value=None):\n",
    "    \"\"\"\n",
    "    This function makes sure that number of channels number is divisible by 8.\n",
    "    Source: https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n",
    "    \"\"\"\n",
    "    if min_value is None:\n",
    "        min_value = divisor\n",
    "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_v < 0.9 * v:\n",
    "        new_v += divisor\n",
    "    return new_v\n",
    "\n",
    "\n",
    "class ConvBnReLU(nn.Module):\n",
    "    \"\"\"\n",
    "    [CONV]-[BN]-[ReLU6]\n",
    "    \"\"\"\n",
    "    def __init__(self, inCh, outCh, stride):\n",
    "        super(ConvBnReLU, self).__init__()\n",
    "        self.inCh = inCh  # Number of input channels\n",
    "        self.outCh = outCh  # Number of output channels\n",
    "        self.stride = stride  # Stride \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(self.inCh, self.outCh, 3, stride=self.stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(outCh),\n",
    "            nn.ReLU6(inplace=True)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "    \n",
    "class InvertedResidual(nn.Module):\n",
    "    \"\"\"\n",
    "    [CONV_1x1-BN-ReLU6]-[CONV_3x3-BN-ReLU6]-[CONV_1x1-BN] with identity shortcut.\n",
    "    \"\"\"\n",
    "    def __init__(self, inCh, outCh, t, s):\n",
    "        super(InvertedResidual, self).__init__()\n",
    "        self.inCh = inCh\n",
    "        self.outCh = outCh\n",
    "        self.t = t  # t: expansion factor\n",
    "        self.s = s  # s: Stride\n",
    "        self.identity_shortcut = (self.inCh == self.outCh) and (self.s == 1) # L:506 Keras official code\n",
    "        \n",
    "        # Bottleneck block\n",
    "        self.block = nn.Sequential(\n",
    "            # Expansition Conv\n",
    "            nn.Conv2d(self.inCh, self.t * self.inCh, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(self.t * self.inCh),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            \n",
    "            # Depthwise Conv\n",
    "            nn.Conv2d(self.t * self.inCh, self.t * self.inCh, kernel_size=3, stride=self.s, padding=1, \n",
    "                      groups=self.t * self.inCh, bias=False),\n",
    "            nn.BatchNorm2d(self.t * self.inCh),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            \n",
    "            # Pointwise Linear Conv (Projection): i.e. No non-linearity\n",
    "            nn.Conv2d(self.t * self.inCh, self.outCh, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(self.outCh), \n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.identity_shortcut:\n",
    "            return x + self.block(x)\n",
    "        else:\n",
    "            return self.block(x)\n",
    "        \n",
    "\n",
    "class PointwiseConv(nn.Module):\n",
    "    def __init__(self, inCh, outCh):\n",
    "        super(PointwiseConv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(inCh, outCh, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(outCh),\n",
    "            nn.ReLU6(inplace=True),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MobileNetV2\n",
    "\n",
    "# Very helpful diagram: https://www.cyberailab.com/home/a-closer-look-at-yolov3\n",
    "# https://github.com/marvis/pytorch-yolo3\n",
    "# https://gitlab.com/EAVISE/lightnet/blob/master/lightnet/network/loss/_regionloss.py\n",
    "\n",
    "class MobileNetV2(nn.Module):\n",
    "    \"\"\"\n",
    "    MobileNetV2 feature extractor for YOLOv3. NOTE: YOLOv3 uses convolutional layers only!\n",
    "    \n",
    "    Input: 416 x 416 x 3\n",
    "    Last layer Pointwise conv output:13 x 13 x 1024 -> Large object detection\n",
    "    5th layer Pointwise conv output: :26 x 26 x 512 -> Medium object detection\n",
    "    3rd layer Pointwise conv output: 52 x 52 x 256 -> Small object detection\n",
    "    \"\"\"\n",
    "    def __init__(self, params):\n",
    "        super(MobileNetV2, self).__init__()\n",
    "        self.params = params\n",
    "        self.first_inCh = 3\n",
    "        last_outCh = 1280\n",
    "        \n",
    "        self.c = [_make_divisible(c * self.params.alpha, 8) for c in self.params.c]\n",
    "        # Last convolution has 1280 output channels for alpha <= 1\n",
    "        self.last_outCh = _make_divisible(int(last_outCh * self.params.alpha), 8) if self.params.alpha > 1.0 else last_outCh\n",
    "        \n",
    "        # NOTE: YOLOv3 makes predictions at 3 different scales: (1) In the last feature map layer: 13 x 13\n",
    "        # (2) The feature map from 2 layers previous and upsample it by 2x: 26 x 26\n",
    "        # (3) The feature map from 2 layers previous and upsample it by 2x: 52 x 52\n",
    "        \n",
    "        # Layer-0\n",
    "        self.layer0 = nn.Sequential(ConvBnReLU(self.first_inCh, self.c[0], self.params.s[0]))\n",
    "        \n",
    "        # Layer-1\n",
    "        self.layer1 = self._make_layer(self.c[0], self.c[1], self.params.t[1], self.params.s[1], self.params.n[1])\n",
    "        \n",
    "        # Layer-2 \n",
    "        self.layer2 = self._make_layer(self.c[1], self.c[2], self.params.t[2], self.params.s[2], self.params.n[2])\n",
    "        \n",
    "        # Layer-3\n",
    "        self.layer3 = self._make_layer(self.c[2], self.c[3], self.params.t[3], self.params.s[3], self.params.n[3])\n",
    "        self.layer3_out = nn.Sequential(PointwiseConv(self.c[3], 256))\n",
    "        \n",
    "        # Layer-4 \n",
    "        self.layer4 = self._make_layer(self.c[3], self.c[4], self.params.t[4], self.params.s[4], self.params.n[4])\n",
    "        \n",
    "        # Layer-5\n",
    "        self.layer5 = self._make_layer(self.c[4], self.c[5], self.params.t[5], self.params.s[5], self.params.n[5])\n",
    "        self.layer5_out = nn.Sequential(PointwiseConv(self.c[5], 512))\n",
    "        \n",
    "        # Layer-6\n",
    "        self.layer6 = self._make_layer(self.c[5], self.c[6], self.params.t[6], self.params.s[6], self.params.n[6])\n",
    "        \n",
    "        # Layer-7\n",
    "        self.layer7 = self._make_layer(self.c[6], self.c[7], self.params.t[7], self.params.s[7], self.params.n[7])\n",
    "        \n",
    "        # Layer-8\n",
    "        self.layer8 = nn.Sequential(PointwiseConv(self.c[7], self.last_outCh))\n",
    "        \n",
    "        \n",
    "        self.out_channels = [256, 512, 1280]\n",
    "        \n",
    "    \n",
    "    def _make_layer(self, inCh, outCh, t, s, n):\n",
    "        layers = []\n",
    "        for i in range(n):\n",
    "            # First layer of each sequence has a stride s and all others use stride 1\n",
    "            if i == 0:\n",
    "                layers.append(InvertedResidual(inCh, outCh, t, s))\n",
    "            else:\n",
    "                layers.append(InvertedResidual(inCh, outCh, t, 1))\n",
    "            \n",
    "            # Update input channel for next IRB layer in the block\n",
    "            inCh = outCh\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        out52 = self.layer3_out(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        out26 = self.layer5_out(x)\n",
    "        x = self.layer6(x)\n",
    "        x = self.layer7(x)\n",
    "        out13 = self.layer8(x)\n",
    "        return out52, out26, out13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52x52 size feature map:  torch.Size([1, 256, 52, 52])\n",
      "26x26 size feature map:  torch.Size([1, 512, 26, 26])\n",
      "13x13 size feature map:  torch.Size([1, 1280, 13, 13])\n"
     ]
    }
   ],
   "source": [
    "# Check\n",
    "params = MobileNetParams()\n",
    "model = MobileNetV2(params)\n",
    "x = torch.randn(1, 3, 416, 416)\n",
    "y52, y26, y13 = model(x)\n",
    "\n",
    "print('52x52 size feature map: ', y52.size())\n",
    "print('26x26 size feature map: ', y26.size())\n",
    "print('13x13 size feature map: ', y13.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 6, 6, 6, 6, 6, 6]\n"
     ]
    }
   ],
   "source": [
    "mp = MobileNetParams()\n",
    "print(mp.t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 6, 6, 6, 6, 6, 6]\n"
     ]
    }
   ],
   "source": [
    "m = MobileNetV2(mp)\n",
    "print(m.params.t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;2mWARNING: Wrong number of channels!\u001b[0m\n",
      "\u001b[0;31;2mTraining\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "WARNING = lambda x: print('\\033[1;31;2mWARNING: ' + x + '\\033[0m')\n",
    "WARNING(\"Wrong number of channels!\")\n",
    "\n",
    "LOG = lambda x: print('\\033[0;31;2m' + x + '\\033[0m')\n",
    "LOG(\"Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
