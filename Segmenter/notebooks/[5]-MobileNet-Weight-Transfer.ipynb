{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image, ImageFilter, ImageOps\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modified MobileNetV2 for DeepLabV3+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_divisible(v, divisor, min_value=None):\n",
    "    \"\"\"\n",
    "    This function makes sure that number of channels number is divisible by 8.\n",
    "    Source: https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n",
    "    \"\"\"\n",
    "    if min_value is None:\n",
    "        min_value = divisor\n",
    "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_v < 0.9 * v:\n",
    "        new_v += divisor\n",
    "    return new_v\n",
    "\n",
    "\n",
    "class ConvBnReLU(nn.Module):\n",
    "    \"\"\"\n",
    "    [CONV]-[BN]-[ReLU6]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, inCh, outCh, stride):\n",
    "        super(ConvBnReLU, self).__init__()\n",
    "        self.inCh = inCh  # Number of input channels\n",
    "        self.outCh = outCh  # Number of output channels\n",
    "        self.stride = stride  # Stride\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(self.inCh, self.outCh, 3, stride=self.stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(outCh),\n",
    "            nn.ReLU6(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class InvertedResidual(nn.Module):\n",
    "    \"\"\"\n",
    "    [EXP:CONV_1x1-BN-ReLU6]-[DW:CONV_3x3-BN-ReLU6]-[PW:CONV_1x1-BN] with identity shortcut \n",
    "    and dilation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, inCh, outCh, t, s, r):\n",
    "        super(InvertedResidual, self).__init__()\n",
    "        self.inCh = inCh\n",
    "        self.outCh = outCh\n",
    "        self.t = t  # t: expansion factor\n",
    "        self.r = r  # r: dilation\n",
    "        if self.r > 1:\n",
    "            self.s = 1  # s: Stride\n",
    "            self.padding = self.r  # Atrous Conv padding same as dilation rate\n",
    "        else:\n",
    "            self.s = s  # s: Stride\n",
    "            self.padding = 1\n",
    "        self.identity_shortcut = (self.inCh == self.outCh) and (self.s == 1)  # L:506 Keras official code\n",
    "\n",
    "        # Bottleneck block\n",
    "        self.block = nn.Sequential(\n",
    "            # Expansition Conv\n",
    "            nn.Conv2d(self.inCh, self.t * self.inCh, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(self.t * self.inCh),\n",
    "            nn.ReLU6(inplace=True),\n",
    "\n",
    "            # Depthwise Conv\n",
    "            nn.Conv2d(self.t * self.inCh, self.t * self.inCh, kernel_size=3, stride=self.s, padding=self.padding, \n",
    "                      dilation=self.r, groups=self.t * self.inCh, bias=False),\n",
    "            nn.BatchNorm2d(self.t * self.inCh),\n",
    "            nn.ReLU6(inplace=True),\n",
    "\n",
    "            # Pointwise Linear Conv (Projection): i.e. No non-linearity\n",
    "            nn.Conv2d(self.t * self.inCh, self.outCh, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(self.outCh),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.identity_shortcut:\n",
    "            return x + self.block(x)\n",
    "        else:\n",
    "            return self.block(x)\n",
    "\n",
    "\n",
    "class PointwiseConv(nn.Module):\n",
    "    def __init__(self, inCh, outCh):\n",
    "        super(PointwiseConv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(inCh, outCh, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(outCh),\n",
    "            nn.ReLU6(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "# MobileNetV2\n",
    "class MobileNetV2(nn.Module):\n",
    "    \"\"\"\n",
    "    MobileNetV2 feature extractor modified to include dilation for DeepLabV3+. \n",
    "    NOTE: Last conv Layer and classification layer removed.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, params):\n",
    "        super(MobileNetV2, self).__init__()\n",
    "        self.params = params\n",
    "        self.first_inCh = 3\n",
    "\n",
    "        self.c = [_make_divisible(c * self.params.alpha, 8) for c in self.params.c]\n",
    "        \n",
    "        # Layer-0\n",
    "        self.layer0 = nn.Sequential(ConvBnReLU(self.first_inCh, self.c[0], self.params.s[0]))\n",
    "\n",
    "        # Layer-1\n",
    "        self.layer1 = self._make_layer(self.c[0], self.c[1], self.params.t[1], self.params.s[1], \n",
    "                                       self.params.n[1], self.params.r[1])\n",
    "\n",
    "        # Layer-2: Image size: 512 -> [IRB-2] -> Output size: 128 (low level feature: 128 * 4 = 512)\n",
    "        self.layer2 = self._make_layer(self.c[1], self.c[2], self.params.t[2], self.params.s[2], \n",
    "                                       self.params.n[2], self.params.r[2])\n",
    "\n",
    "        # Layer-3\n",
    "        self.layer3 = self._make_layer(self.c[2], self.c[3], self.params.t[3], self.params.s[3], \n",
    "                                       self.params.n[3], self.params.r[3])\n",
    "\n",
    "        # Layer-4\n",
    "        self.layer4 = self._make_layer(self.c[3], self.c[4], self.params.t[4], self.params.s[4], \n",
    "                                       self.params.n[4], self.params.r[4])\n",
    "\n",
    "        # Layer-5: Image size: 512 -> [IRB-5] -> Output size: 32, so output stride = 16 achieved\n",
    "        self.layer5 = self._make_layer(self.c[4], self.c[5], self.params.t[5], self.params.s[5], \n",
    "                                       self.params.n[5], self.params.r[5])\n",
    "\n",
    "        # Layer-6: Apply dilation rate = 2\n",
    "        self.layer6 = self._make_layer(self.c[5], self.c[6], self.params.t[6], self.params.s[6], \n",
    "                                       self.params.n[6], self.params.r[6])\n",
    "\n",
    "        # Layer-7: Apply dilation rate = 2\n",
    "        self.layer7 = self._make_layer(self.c[6], self.c[7], self.params.t[7], self.params.s[7], \n",
    "                                       self.params.n[7], self.params.r[7])\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _make_layer(self, inCh, outCh, t, s, n, r):\n",
    "        layers = []\n",
    "        for i in range(n):\n",
    "            # First layer of each sequence has a stride s and all others use stride 1\n",
    "            if i == 0:\n",
    "                layers.append(InvertedResidual(inCh, outCh, t, s, r))\n",
    "            else:\n",
    "                layers.append(InvertedResidual(inCh, outCh, t, 1, r))\n",
    "\n",
    "            # Update input channel for next IRB layer in the block\n",
    "            inCh = outCh\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        low_level_features = self.layer2(x)  # [512, 512]/4 = [128, 128] \n",
    "        x = self.layer3(low_level_features)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        x = self.layer6(x)\n",
    "        x = self.layer7(x)\n",
    "        return x, low_level_features\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "                \n",
    "\n",
    "def MobileNet(pretrained=True, **kwargs):\n",
    "    \"\"\"\n",
    "    Constructs a MobileNet V2 model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    pretrained: bool, use ImageNet pretrained model or not.\n",
    "    n_class: int, 1000 classes in ImageNet data.\n",
    "    weight_file: str, path to pretrained weights\n",
    "    \"\"\"\n",
    "    weight_file = kwargs.pop('weight_file', '')\n",
    "    model = MobileNetV2(**kwargs)\n",
    "    if pretrained:\n",
    "        state_dict = torch.load(weight_file)\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config():\n",
    "    \"\"\"\n",
    "    Configuration for training DeepLabV3+\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # MobileNetV2 parameters\n",
    "        # ----------------------\n",
    "        self.pretrained = False\n",
    "        # Conv and Inverted Residual Parameters: Table-2 (https://arxiv.org/pdf/1801.04381.pdf)\n",
    "        self.t = [1, 1, 6, 6, 6, 6, 6, 6]  # t: expansion factor\n",
    "        self.c = [32, 16, 24, 32, 64, 96, 160, 320]  # c: Output channels\n",
    "        self.n = [1, 1, 2, 3, 4, 3, 3, 1]  # n: Number of times layer is repeated\n",
    "        self.s = [2, 1, 2, 2, 2, 1, 2, 1]  # s: Stride\n",
    "        self.r = [1, 1, 1, 1, 1, 1, 2, 2]  # r: Dilation (added to take care of dilation)\n",
    "        # Width multiplier: Controls the width of the network\n",
    "        self.alpha = 1 # Use multiples of 0.25, min=0.25, max=1.0\n",
    "        \n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MobileNet Pre-trained on ImageNet - Weight Transfer\n",
    "\n",
    "\n",
    "[Example](https://github.com/lizhengwei1992/mobilenetv2_deeplabv3_pytorch/blob/master/utils.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of keys (pre-trained):  267\n"
     ]
    }
   ],
   "source": [
    "# Model pre-trained on ImageNet weights\n",
    "trained_state_dict = torch.load('./MobileNetV2.pth.tar')\n",
    "trained_keys = list(trained_state_dict['state_dict'].keys())\n",
    "print('Number of keys (pre-trained): ', len(trained_keys))\n",
    "trained_weights = list(trained_state_dict['state_dict'].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of keys (modified):  312\n"
     ]
    }
   ],
   "source": [
    "# Modified MobileNet\n",
    "model = MobileNetV2(params=config)\n",
    "model_keys = list(model.state_dict().keys())\n",
    "print('Number of keys (modified): ', len(model_keys))\n",
    "model_weights = list(model.state_dict().values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "260\n"
     ]
    }
   ],
   "source": [
    "# Tensors with size []\n",
    "print(312 - sum([k.endswith('num_batches_tracked') for k in model_keys]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'layer2.1.block.7.num_batches_tracked'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ignore_indices = [i for i, k in enumerate(model_keys) if k.endswith('num_batches_tracked')]\n",
    "model_keys[ignore_indices[9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([32, 3, 3, 3]) --->  layer0.0.conv.0.weight\n",
      "1 torch.Size([32]) --->  layer0.0.conv.1.weight\n",
      "2 torch.Size([32]) --->  layer0.0.conv.1.bias\n",
      "3 torch.Size([32]) --->  layer0.0.conv.1.running_mean\n",
      "4 torch.Size([32]) --->  layer0.0.conv.1.running_var\n",
      "6 torch.Size([32, 32, 1, 1]) --->  layer1.0.block.0.weight\n",
      "7 torch.Size([32]) --->  layer1.0.block.1.weight\n",
      "8 torch.Size([32]) --->  layer1.0.block.1.bias\n",
      "9 torch.Size([32]) --->  layer1.0.block.1.running_mean\n",
      "10 torch.Size([32]) --->  layer1.0.block.1.running_var\n",
      "12 torch.Size([32, 1, 3, 3]) --->  layer1.0.block.3.weight\n",
      "13 torch.Size([32]) --->  layer1.0.block.4.weight\n",
      "14 torch.Size([32]) --->  layer1.0.block.4.bias\n",
      "15 torch.Size([32]) --->  layer1.0.block.4.running_mean\n",
      "16 torch.Size([32]) --->  layer1.0.block.4.running_var\n",
      "18 torch.Size([16, 32, 1, 1]) --->  layer1.0.block.6.weight\n",
      "19 torch.Size([16]) --->  layer1.0.block.7.weight\n",
      "20 torch.Size([16]) --->  layer1.0.block.7.bias\n",
      "21 torch.Size([16]) --->  layer1.0.block.7.running_mean\n",
      "22 torch.Size([16]) --->  layer1.0.block.7.running_var\n",
      "24 torch.Size([96, 16, 1, 1]) --->  layer2.0.block.0.weight\n",
      "25 torch.Size([96]) --->  layer2.0.block.1.weight\n",
      "26 torch.Size([96]) --->  layer2.0.block.1.bias\n",
      "27 torch.Size([96]) --->  layer2.0.block.1.running_mean\n",
      "28 torch.Size([96]) --->  layer2.0.block.1.running_var\n",
      "30 torch.Size([96, 1, 3, 3]) --->  layer2.0.block.3.weight\n",
      "31 torch.Size([96]) --->  layer2.0.block.4.weight\n",
      "32 torch.Size([96]) --->  layer2.0.block.4.bias\n",
      "33 torch.Size([96]) --->  layer2.0.block.4.running_mean\n",
      "34 torch.Size([96]) --->  layer2.0.block.4.running_var\n",
      "36 torch.Size([24, 96, 1, 1]) --->  layer2.0.block.6.weight\n",
      "37 torch.Size([24]) --->  layer2.0.block.7.weight\n",
      "38 torch.Size([24]) --->  layer2.0.block.7.bias\n",
      "39 torch.Size([24]) --->  layer2.0.block.7.running_mean\n",
      "40 torch.Size([24]) --->  layer2.0.block.7.running_var\n",
      "42 torch.Size([144, 24, 1, 1]) --->  layer2.1.block.0.weight\n",
      "43 torch.Size([144]) --->  layer2.1.block.1.weight\n",
      "44 torch.Size([144]) --->  layer2.1.block.1.bias\n",
      "45 torch.Size([144]) --->  layer2.1.block.1.running_mean\n",
      "46 torch.Size([144]) --->  layer2.1.block.1.running_var\n",
      "48 torch.Size([144, 1, 3, 3]) --->  layer2.1.block.3.weight\n",
      "49 torch.Size([144]) --->  layer2.1.block.4.weight\n",
      "50 torch.Size([144]) --->  layer2.1.block.4.bias\n",
      "51 torch.Size([144]) --->  layer2.1.block.4.running_mean\n",
      "52 torch.Size([144]) --->  layer2.1.block.4.running_var\n",
      "54 torch.Size([24, 144, 1, 1]) --->  layer2.1.block.6.weight\n",
      "55 torch.Size([24]) --->  layer2.1.block.7.weight\n",
      "56 torch.Size([24]) --->  layer2.1.block.7.bias\n",
      "57 torch.Size([24]) --->  layer2.1.block.7.running_mean\n",
      "58 torch.Size([24]) --->  layer2.1.block.7.running_var\n",
      "60 torch.Size([144, 24, 1, 1]) --->  layer3.0.block.0.weight\n",
      "61 torch.Size([144]) --->  layer3.0.block.1.weight\n",
      "62 torch.Size([144]) --->  layer3.0.block.1.bias\n",
      "63 torch.Size([144]) --->  layer3.0.block.1.running_mean\n",
      "64 torch.Size([144]) --->  layer3.0.block.1.running_var\n",
      "66 torch.Size([144, 1, 3, 3]) --->  layer3.0.block.3.weight\n",
      "67 torch.Size([144]) --->  layer3.0.block.4.weight\n",
      "68 torch.Size([144]) --->  layer3.0.block.4.bias\n",
      "69 torch.Size([144]) --->  layer3.0.block.4.running_mean\n",
      "70 torch.Size([144]) --->  layer3.0.block.4.running_var\n",
      "72 torch.Size([32, 144, 1, 1]) --->  layer3.0.block.6.weight\n",
      "73 torch.Size([32]) --->  layer3.0.block.7.weight\n",
      "74 torch.Size([32]) --->  layer3.0.block.7.bias\n",
      "75 torch.Size([32]) --->  layer3.0.block.7.running_mean\n",
      "76 torch.Size([32]) --->  layer3.0.block.7.running_var\n",
      "78 torch.Size([192, 32, 1, 1]) --->  layer3.1.block.0.weight\n",
      "79 torch.Size([192]) --->  layer3.1.block.1.weight\n",
      "80 torch.Size([192]) --->  layer3.1.block.1.bias\n",
      "81 torch.Size([192]) --->  layer3.1.block.1.running_mean\n",
      "82 torch.Size([192]) --->  layer3.1.block.1.running_var\n",
      "84 torch.Size([192, 1, 3, 3]) --->  layer3.1.block.3.weight\n",
      "85 torch.Size([192]) --->  layer3.1.block.4.weight\n",
      "86 torch.Size([192]) --->  layer3.1.block.4.bias\n",
      "87 torch.Size([192]) --->  layer3.1.block.4.running_mean\n",
      "88 torch.Size([192]) --->  layer3.1.block.4.running_var\n",
      "90 torch.Size([32, 192, 1, 1]) --->  layer3.1.block.6.weight\n",
      "91 torch.Size([32]) --->  layer3.1.block.7.weight\n",
      "92 torch.Size([32]) --->  layer3.1.block.7.bias\n",
      "93 torch.Size([32]) --->  layer3.1.block.7.running_mean\n",
      "94 torch.Size([32]) --->  layer3.1.block.7.running_var\n",
      "96 torch.Size([192, 32, 1, 1]) --->  layer3.2.block.0.weight\n",
      "97 torch.Size([192]) --->  layer3.2.block.1.weight\n",
      "98 torch.Size([192]) --->  layer3.2.block.1.bias\n",
      "99 torch.Size([192]) --->  layer3.2.block.1.running_mean\n",
      "100 torch.Size([192]) --->  layer3.2.block.1.running_var\n",
      "102 torch.Size([192, 1, 3, 3]) --->  layer3.2.block.3.weight\n",
      "103 torch.Size([192]) --->  layer3.2.block.4.weight\n",
      "104 torch.Size([192]) --->  layer3.2.block.4.bias\n",
      "105 torch.Size([192]) --->  layer3.2.block.4.running_mean\n",
      "106 torch.Size([192]) --->  layer3.2.block.4.running_var\n",
      "108 torch.Size([32, 192, 1, 1]) --->  layer3.2.block.6.weight\n",
      "109 torch.Size([32]) --->  layer3.2.block.7.weight\n",
      "110 torch.Size([32]) --->  layer3.2.block.7.bias\n",
      "111 torch.Size([32]) --->  layer3.2.block.7.running_mean\n",
      "112 torch.Size([32]) --->  layer3.2.block.7.running_var\n",
      "114 torch.Size([192, 32, 1, 1]) --->  layer4.0.block.0.weight\n",
      "115 torch.Size([192]) --->  layer4.0.block.1.weight\n",
      "116 torch.Size([192]) --->  layer4.0.block.1.bias\n",
      "117 torch.Size([192]) --->  layer4.0.block.1.running_mean\n",
      "118 torch.Size([192]) --->  layer4.0.block.1.running_var\n",
      "120 torch.Size([192, 1, 3, 3]) --->  layer4.0.block.3.weight\n",
      "121 torch.Size([192]) --->  layer4.0.block.4.weight\n",
      "122 torch.Size([192]) --->  layer4.0.block.4.bias\n",
      "123 torch.Size([192]) --->  layer4.0.block.4.running_mean\n",
      "124 torch.Size([192]) --->  layer4.0.block.4.running_var\n",
      "126 torch.Size([64, 192, 1, 1]) --->  layer4.0.block.6.weight\n",
      "127 torch.Size([64]) --->  layer4.0.block.7.weight\n",
      "128 torch.Size([64]) --->  layer4.0.block.7.bias\n",
      "129 torch.Size([64]) --->  layer4.0.block.7.running_mean\n",
      "130 torch.Size([64]) --->  layer4.0.block.7.running_var\n",
      "132 torch.Size([384, 64, 1, 1]) --->  layer4.1.block.0.weight\n",
      "133 torch.Size([384]) --->  layer4.1.block.1.weight\n",
      "134 torch.Size([384]) --->  layer4.1.block.1.bias\n",
      "135 torch.Size([384]) --->  layer4.1.block.1.running_mean\n",
      "136 torch.Size([384]) --->  layer4.1.block.1.running_var\n",
      "138 torch.Size([384, 1, 3, 3]) --->  layer4.1.block.3.weight\n",
      "139 torch.Size([384]) --->  layer4.1.block.4.weight\n",
      "140 torch.Size([384]) --->  layer4.1.block.4.bias\n",
      "141 torch.Size([384]) --->  layer4.1.block.4.running_mean\n",
      "142 torch.Size([384]) --->  layer4.1.block.4.running_var\n",
      "144 torch.Size([64, 384, 1, 1]) --->  layer4.1.block.6.weight\n",
      "145 torch.Size([64]) --->  layer4.1.block.7.weight\n",
      "146 torch.Size([64]) --->  layer4.1.block.7.bias\n",
      "147 torch.Size([64]) --->  layer4.1.block.7.running_mean\n",
      "148 torch.Size([64]) --->  layer4.1.block.7.running_var\n",
      "150 torch.Size([384, 64, 1, 1]) --->  layer4.2.block.0.weight\n",
      "151 torch.Size([384]) --->  layer4.2.block.1.weight\n",
      "152 torch.Size([384]) --->  layer4.2.block.1.bias\n",
      "153 torch.Size([384]) --->  layer4.2.block.1.running_mean\n",
      "154 torch.Size([384]) --->  layer4.2.block.1.running_var\n",
      "156 torch.Size([384, 1, 3, 3]) --->  layer4.2.block.3.weight\n",
      "157 torch.Size([384]) --->  layer4.2.block.4.weight\n",
      "158 torch.Size([384]) --->  layer4.2.block.4.bias\n",
      "159 torch.Size([384]) --->  layer4.2.block.4.running_mean\n",
      "160 torch.Size([384]) --->  layer4.2.block.4.running_var\n",
      "162 torch.Size([64, 384, 1, 1]) --->  layer4.2.block.6.weight\n",
      "163 torch.Size([64]) --->  layer4.2.block.7.weight\n",
      "164 torch.Size([64]) --->  layer4.2.block.7.bias\n",
      "165 torch.Size([64]) --->  layer4.2.block.7.running_mean\n",
      "166 torch.Size([64]) --->  layer4.2.block.7.running_var\n",
      "168 torch.Size([384, 64, 1, 1]) --->  layer4.3.block.0.weight\n",
      "169 torch.Size([384]) --->  layer4.3.block.1.weight\n",
      "170 torch.Size([384]) --->  layer4.3.block.1.bias\n",
      "171 torch.Size([384]) --->  layer4.3.block.1.running_mean\n",
      "172 torch.Size([384]) --->  layer4.3.block.1.running_var\n",
      "174 torch.Size([384, 1, 3, 3]) --->  layer4.3.block.3.weight\n",
      "175 torch.Size([384]) --->  layer4.3.block.4.weight\n",
      "176 torch.Size([384]) --->  layer4.3.block.4.bias\n",
      "177 torch.Size([384]) --->  layer4.3.block.4.running_mean\n",
      "178 torch.Size([384]) --->  layer4.3.block.4.running_var\n",
      "180 torch.Size([64, 384, 1, 1]) --->  layer4.3.block.6.weight\n",
      "181 torch.Size([64]) --->  layer4.3.block.7.weight\n",
      "182 torch.Size([64]) --->  layer4.3.block.7.bias\n",
      "183 torch.Size([64]) --->  layer4.3.block.7.running_mean\n",
      "184 torch.Size([64]) --->  layer4.3.block.7.running_var\n",
      "186 torch.Size([384, 64, 1, 1]) --->  layer5.0.block.0.weight\n",
      "187 torch.Size([384]) --->  layer5.0.block.1.weight\n",
      "188 torch.Size([384]) --->  layer5.0.block.1.bias\n",
      "189 torch.Size([384]) --->  layer5.0.block.1.running_mean\n",
      "190 torch.Size([384]) --->  layer5.0.block.1.running_var\n",
      "192 torch.Size([384, 1, 3, 3]) --->  layer5.0.block.3.weight\n",
      "193 torch.Size([384]) --->  layer5.0.block.4.weight\n",
      "194 torch.Size([384]) --->  layer5.0.block.4.bias\n",
      "195 torch.Size([384]) --->  layer5.0.block.4.running_mean\n",
      "196 torch.Size([384]) --->  layer5.0.block.4.running_var\n",
      "198 torch.Size([96, 384, 1, 1]) --->  layer5.0.block.6.weight\n",
      "199 torch.Size([96]) --->  layer5.0.block.7.weight\n",
      "200 torch.Size([96]) --->  layer5.0.block.7.bias\n",
      "201 torch.Size([96]) --->  layer5.0.block.7.running_mean\n",
      "202 torch.Size([96]) --->  layer5.0.block.7.running_var\n",
      "204 torch.Size([576, 96, 1, 1]) --->  layer5.1.block.0.weight\n",
      "205 torch.Size([576]) --->  layer5.1.block.1.weight\n",
      "206 torch.Size([576]) --->  layer5.1.block.1.bias\n",
      "207 torch.Size([576]) --->  layer5.1.block.1.running_mean\n",
      "208 torch.Size([576]) --->  layer5.1.block.1.running_var\n",
      "210 torch.Size([576, 1, 3, 3]) --->  layer5.1.block.3.weight\n",
      "211 torch.Size([576]) --->  layer5.1.block.4.weight\n",
      "212 torch.Size([576]) --->  layer5.1.block.4.bias\n",
      "213 torch.Size([576]) --->  layer5.1.block.4.running_mean\n",
      "214 torch.Size([576]) --->  layer5.1.block.4.running_var\n",
      "216 torch.Size([96, 576, 1, 1]) --->  layer5.1.block.6.weight\n",
      "217 torch.Size([96]) --->  layer5.1.block.7.weight\n",
      "218 torch.Size([96]) --->  layer5.1.block.7.bias\n",
      "219 torch.Size([96]) --->  layer5.1.block.7.running_mean\n",
      "220 torch.Size([96]) --->  layer5.1.block.7.running_var\n",
      "222 torch.Size([576, 96, 1, 1]) --->  layer5.2.block.0.weight\n",
      "223 torch.Size([576]) --->  layer5.2.block.1.weight\n",
      "224 torch.Size([576]) --->  layer5.2.block.1.bias\n",
      "225 torch.Size([576]) --->  layer5.2.block.1.running_mean\n",
      "226 torch.Size([576]) --->  layer5.2.block.1.running_var\n",
      "228 torch.Size([576, 1, 3, 3]) --->  layer5.2.block.3.weight\n",
      "229 torch.Size([576]) --->  layer5.2.block.4.weight\n",
      "230 torch.Size([576]) --->  layer5.2.block.4.bias\n",
      "231 torch.Size([576]) --->  layer5.2.block.4.running_mean\n",
      "232 torch.Size([576]) --->  layer5.2.block.4.running_var\n",
      "234 torch.Size([96, 576, 1, 1]) --->  layer5.2.block.6.weight\n",
      "235 torch.Size([96]) --->  layer5.2.block.7.weight\n",
      "236 torch.Size([96]) --->  layer5.2.block.7.bias\n",
      "237 torch.Size([96]) --->  layer5.2.block.7.running_mean\n",
      "238 torch.Size([96]) --->  layer5.2.block.7.running_var\n",
      "240 torch.Size([576, 96, 1, 1]) --->  layer6.0.block.0.weight\n",
      "241 torch.Size([576]) --->  layer6.0.block.1.weight\n",
      "242 torch.Size([576]) --->  layer6.0.block.1.bias\n",
      "243 torch.Size([576]) --->  layer6.0.block.1.running_mean\n",
      "244 torch.Size([576]) --->  layer6.0.block.1.running_var\n",
      "246 torch.Size([576, 1, 3, 3]) --->  layer6.0.block.3.weight\n",
      "247 torch.Size([576]) --->  layer6.0.block.4.weight\n",
      "248 torch.Size([576]) --->  layer6.0.block.4.bias\n",
      "249 torch.Size([576]) --->  layer6.0.block.4.running_mean\n",
      "250 torch.Size([576]) --->  layer6.0.block.4.running_var\n",
      "252 torch.Size([160, 576, 1, 1]) --->  layer6.0.block.6.weight\n",
      "253 torch.Size([160]) --->  layer6.0.block.7.weight\n",
      "254 torch.Size([160]) --->  layer6.0.block.7.bias\n",
      "255 torch.Size([160]) --->  layer6.0.block.7.running_mean\n",
      "256 torch.Size([160]) --->  layer6.0.block.7.running_var\n",
      "258 torch.Size([960, 160, 1, 1]) --->  layer6.1.block.0.weight\n",
      "259 torch.Size([960]) --->  layer6.1.block.1.weight\n",
      "260 torch.Size([960]) --->  layer6.1.block.1.bias\n",
      "261 torch.Size([960]) --->  layer6.1.block.1.running_mean\n",
      "262 torch.Size([960]) --->  layer6.1.block.1.running_var\n",
      "264 torch.Size([960, 1, 3, 3]) --->  layer6.1.block.3.weight\n",
      "265 torch.Size([960]) --->  layer6.1.block.4.weight\n",
      "266 torch.Size([960]) --->  layer6.1.block.4.bias\n",
      "267 torch.Size([960]) --->  layer6.1.block.4.running_mean\n",
      "268 torch.Size([960]) --->  layer6.1.block.4.running_var\n",
      "270 torch.Size([160, 960, 1, 1]) --->  layer6.1.block.6.weight\n",
      "271 torch.Size([160]) --->  layer6.1.block.7.weight\n",
      "272 torch.Size([160]) --->  layer6.1.block.7.bias\n",
      "273 torch.Size([160]) --->  layer6.1.block.7.running_mean\n",
      "274 torch.Size([160]) --->  layer6.1.block.7.running_var\n",
      "276 torch.Size([960, 160, 1, 1]) --->  layer6.2.block.0.weight\n",
      "277 torch.Size([960]) --->  layer6.2.block.1.weight\n",
      "278 torch.Size([960]) --->  layer6.2.block.1.bias\n",
      "279 torch.Size([960]) --->  layer6.2.block.1.running_mean\n",
      "280 torch.Size([960]) --->  layer6.2.block.1.running_var\n",
      "282 torch.Size([960, 1, 3, 3]) --->  layer6.2.block.3.weight\n",
      "283 torch.Size([960]) --->  layer6.2.block.4.weight\n",
      "284 torch.Size([960]) --->  layer6.2.block.4.bias\n",
      "285 torch.Size([960]) --->  layer6.2.block.4.running_mean\n",
      "286 torch.Size([960]) --->  layer6.2.block.4.running_var\n",
      "288 torch.Size([160, 960, 1, 1]) --->  layer6.2.block.6.weight\n",
      "289 torch.Size([160]) --->  layer6.2.block.7.weight\n",
      "290 torch.Size([160]) --->  layer6.2.block.7.bias\n",
      "291 torch.Size([160]) --->  layer6.2.block.7.running_mean\n",
      "292 torch.Size([160]) --->  layer6.2.block.7.running_var\n",
      "294 torch.Size([960, 160, 1, 1]) --->  layer7.0.block.0.weight\n",
      "295 torch.Size([960]) --->  layer7.0.block.1.weight\n",
      "296 torch.Size([960]) --->  layer7.0.block.1.bias\n",
      "297 torch.Size([960]) --->  layer7.0.block.1.running_mean\n",
      "298 torch.Size([960]) --->  layer7.0.block.1.running_var\n",
      "300 torch.Size([960, 1, 3, 3]) --->  layer7.0.block.3.weight\n",
      "301 torch.Size([960]) --->  layer7.0.block.4.weight\n",
      "302 torch.Size([960]) --->  layer7.0.block.4.bias\n",
      "303 torch.Size([960]) --->  layer7.0.block.4.running_mean\n",
      "304 torch.Size([960]) --->  layer7.0.block.4.running_var\n",
      "306 torch.Size([320, 960, 1, 1]) --->  layer7.0.block.6.weight\n",
      "307 torch.Size([320]) --->  layer7.0.block.7.weight\n",
      "308 torch.Size([320]) --->  layer7.0.block.7.bias\n",
      "309 torch.Size([320]) --->  layer7.0.block.7.running_mean\n",
      "310 torch.Size([320]) --->  layer7.0.block.7.running_var\n",
      "\n",
      "Number of weights:  260\n"
     ]
    }
   ],
   "source": [
    "_model_keys = []\n",
    "_model_key_ids = []\n",
    "for i, w in enumerate(model_weights):\n",
    "    if i not in ignore_indices:\n",
    "        _model_keys.append(model_keys[i])\n",
    "        _model_key_ids.append(i)\n",
    "        print(i, w.size(), '---> ', model_keys[i])\n",
    "\n",
    "print()\n",
    "print('Number of weights: ', len(_model_keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([32, 3, 3, 3]) --->  module.conv1.weight\n",
      "1 torch.Size([32]) --->  module.bn1.weight\n",
      "2 torch.Size([32]) --->  module.bn1.bias\n",
      "3 torch.Size([32]) --->  module.bn1.running_mean\n",
      "4 torch.Size([32]) --->  module.bn1.running_var\n",
      "5 torch.Size([32, 32, 1, 1]) --->  module.bottlenecks.Bottlenecks_0.LinearBottleneck0_0.conv1.weight\n",
      "6 torch.Size([32]) --->  module.bottlenecks.Bottlenecks_0.LinearBottleneck0_0.bn1.weight\n",
      "7 torch.Size([32]) --->  module.bottlenecks.Bottlenecks_0.LinearBottleneck0_0.bn1.bias\n",
      "8 torch.Size([32]) --->  module.bottlenecks.Bottlenecks_0.LinearBottleneck0_0.bn1.running_mean\n",
      "9 torch.Size([32]) --->  module.bottlenecks.Bottlenecks_0.LinearBottleneck0_0.bn1.running_var\n",
      "10 torch.Size([32, 1, 3, 3]) --->  module.bottlenecks.Bottlenecks_0.LinearBottleneck0_0.conv2.weight\n",
      "11 torch.Size([32]) --->  module.bottlenecks.Bottlenecks_0.LinearBottleneck0_0.bn2.weight\n",
      "12 torch.Size([32]) --->  module.bottlenecks.Bottlenecks_0.LinearBottleneck0_0.bn2.bias\n",
      "13 torch.Size([32]) --->  module.bottlenecks.Bottlenecks_0.LinearBottleneck0_0.bn2.running_mean\n",
      "14 torch.Size([32]) --->  module.bottlenecks.Bottlenecks_0.LinearBottleneck0_0.bn2.running_var\n",
      "15 torch.Size([16, 32, 1, 1]) --->  module.bottlenecks.Bottlenecks_0.LinearBottleneck0_0.conv3.weight\n",
      "16 torch.Size([16]) --->  module.bottlenecks.Bottlenecks_0.LinearBottleneck0_0.bn3.weight\n",
      "17 torch.Size([16]) --->  module.bottlenecks.Bottlenecks_0.LinearBottleneck0_0.bn3.bias\n",
      "18 torch.Size([16]) --->  module.bottlenecks.Bottlenecks_0.LinearBottleneck0_0.bn3.running_mean\n",
      "19 torch.Size([16]) --->  module.bottlenecks.Bottlenecks_0.LinearBottleneck0_0.bn3.running_var\n",
      "20 torch.Size([96, 16, 1, 1]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_0.conv1.weight\n",
      "21 torch.Size([96]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_0.bn1.weight\n",
      "22 torch.Size([96]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_0.bn1.bias\n",
      "23 torch.Size([96]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_0.bn1.running_mean\n",
      "24 torch.Size([96]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_0.bn1.running_var\n",
      "25 torch.Size([96, 1, 3, 3]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_0.conv2.weight\n",
      "26 torch.Size([96]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_0.bn2.weight\n",
      "27 torch.Size([96]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_0.bn2.bias\n",
      "28 torch.Size([96]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_0.bn2.running_mean\n",
      "29 torch.Size([96]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_0.bn2.running_var\n",
      "30 torch.Size([24, 96, 1, 1]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_0.conv3.weight\n",
      "31 torch.Size([24]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_0.bn3.weight\n",
      "32 torch.Size([24]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_0.bn3.bias\n",
      "33 torch.Size([24]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_0.bn3.running_mean\n",
      "34 torch.Size([24]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_0.bn3.running_var\n",
      "35 torch.Size([144, 24, 1, 1]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_1.conv1.weight\n",
      "36 torch.Size([144]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_1.bn1.weight\n",
      "37 torch.Size([144]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_1.bn1.bias\n",
      "38 torch.Size([144]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_1.bn1.running_mean\n",
      "39 torch.Size([144]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_1.bn1.running_var\n",
      "40 torch.Size([144, 1, 3, 3]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_1.conv2.weight\n",
      "41 torch.Size([144]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_1.bn2.weight\n",
      "42 torch.Size([144]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_1.bn2.bias\n",
      "43 torch.Size([144]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_1.bn2.running_mean\n",
      "44 torch.Size([144]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_1.bn2.running_var\n",
      "45 torch.Size([24, 144, 1, 1]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_1.conv3.weight\n",
      "46 torch.Size([24]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_1.bn3.weight\n",
      "47 torch.Size([24]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_1.bn3.bias\n",
      "48 torch.Size([24]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_1.bn3.running_mean\n",
      "49 torch.Size([24]) --->  module.bottlenecks.Bottlenecks_1.LinearBottleneck1_1.bn3.running_var\n",
      "50 torch.Size([144, 24, 1, 1]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_0.conv1.weight\n",
      "51 torch.Size([144]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_0.bn1.weight\n",
      "52 torch.Size([144]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_0.bn1.bias\n",
      "53 torch.Size([144]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_0.bn1.running_mean\n",
      "54 torch.Size([144]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_0.bn1.running_var\n",
      "55 torch.Size([144, 1, 3, 3]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_0.conv2.weight\n",
      "56 torch.Size([144]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_0.bn2.weight\n",
      "57 torch.Size([144]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_0.bn2.bias\n",
      "58 torch.Size([144]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_0.bn2.running_mean\n",
      "59 torch.Size([144]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_0.bn2.running_var\n",
      "60 torch.Size([32, 144, 1, 1]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_0.conv3.weight\n",
      "61 torch.Size([32]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_0.bn3.weight\n",
      "62 torch.Size([32]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_0.bn3.bias\n",
      "63 torch.Size([32]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_0.bn3.running_mean\n",
      "64 torch.Size([32]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_0.bn3.running_var\n",
      "65 torch.Size([192, 32, 1, 1]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_1.conv1.weight\n",
      "66 torch.Size([192]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_1.bn1.weight\n",
      "67 torch.Size([192]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_1.bn1.bias\n",
      "68 torch.Size([192]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_1.bn1.running_mean\n",
      "69 torch.Size([192]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_1.bn1.running_var\n",
      "70 torch.Size([192, 1, 3, 3]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_1.conv2.weight\n",
      "71 torch.Size([192]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_1.bn2.weight\n",
      "72 torch.Size([192]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_1.bn2.bias\n",
      "73 torch.Size([192]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_1.bn2.running_mean\n",
      "74 torch.Size([192]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_1.bn2.running_var\n",
      "75 torch.Size([32, 192, 1, 1]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_1.conv3.weight\n",
      "76 torch.Size([32]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_1.bn3.weight\n",
      "77 torch.Size([32]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_1.bn3.bias\n",
      "78 torch.Size([32]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_1.bn3.running_mean\n",
      "79 torch.Size([32]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_1.bn3.running_var\n",
      "80 torch.Size([192, 32, 1, 1]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_2.conv1.weight\n",
      "81 torch.Size([192]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_2.bn1.weight\n",
      "82 torch.Size([192]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_2.bn1.bias\n",
      "83 torch.Size([192]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_2.bn1.running_mean\n",
      "84 torch.Size([192]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_2.bn1.running_var\n",
      "85 torch.Size([192, 1, 3, 3]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_2.conv2.weight\n",
      "86 torch.Size([192]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_2.bn2.weight\n",
      "87 torch.Size([192]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_2.bn2.bias\n",
      "88 torch.Size([192]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_2.bn2.running_mean\n",
      "89 torch.Size([192]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_2.bn2.running_var\n",
      "90 torch.Size([32, 192, 1, 1]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_2.conv3.weight\n",
      "91 torch.Size([32]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_2.bn3.weight\n",
      "92 torch.Size([32]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_2.bn3.bias\n",
      "93 torch.Size([32]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_2.bn3.running_mean\n",
      "94 torch.Size([32]) --->  module.bottlenecks.Bottlenecks_2.LinearBottleneck2_2.bn3.running_var\n",
      "95 torch.Size([192, 32, 1, 1]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_0.conv1.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96 torch.Size([192]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_0.bn1.weight\n",
      "97 torch.Size([192]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_0.bn1.bias\n",
      "98 torch.Size([192]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_0.bn1.running_mean\n",
      "99 torch.Size([192]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_0.bn1.running_var\n",
      "100 torch.Size([192, 1, 3, 3]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_0.conv2.weight\n",
      "101 torch.Size([192]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_0.bn2.weight\n",
      "102 torch.Size([192]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_0.bn2.bias\n",
      "103 torch.Size([192]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_0.bn2.running_mean\n",
      "104 torch.Size([192]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_0.bn2.running_var\n",
      "105 torch.Size([64, 192, 1, 1]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_0.conv3.weight\n",
      "106 torch.Size([64]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_0.bn3.weight\n",
      "107 torch.Size([64]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_0.bn3.bias\n",
      "108 torch.Size([64]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_0.bn3.running_mean\n",
      "109 torch.Size([64]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_0.bn3.running_var\n",
      "110 torch.Size([384, 64, 1, 1]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_1.conv1.weight\n",
      "111 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_1.bn1.weight\n",
      "112 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_1.bn1.bias\n",
      "113 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_1.bn1.running_mean\n",
      "114 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_1.bn1.running_var\n",
      "115 torch.Size([384, 1, 3, 3]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_1.conv2.weight\n",
      "116 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_1.bn2.weight\n",
      "117 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_1.bn2.bias\n",
      "118 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_1.bn2.running_mean\n",
      "119 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_1.bn2.running_var\n",
      "120 torch.Size([64, 384, 1, 1]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_1.conv3.weight\n",
      "121 torch.Size([64]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_1.bn3.weight\n",
      "122 torch.Size([64]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_1.bn3.bias\n",
      "123 torch.Size([64]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_1.bn3.running_mean\n",
      "124 torch.Size([64]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_1.bn3.running_var\n",
      "125 torch.Size([384, 64, 1, 1]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_2.conv1.weight\n",
      "126 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_2.bn1.weight\n",
      "127 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_2.bn1.bias\n",
      "128 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_2.bn1.running_mean\n",
      "129 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_2.bn1.running_var\n",
      "130 torch.Size([384, 1, 3, 3]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_2.conv2.weight\n",
      "131 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_2.bn2.weight\n",
      "132 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_2.bn2.bias\n",
      "133 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_2.bn2.running_mean\n",
      "134 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_2.bn2.running_var\n",
      "135 torch.Size([64, 384, 1, 1]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_2.conv3.weight\n",
      "136 torch.Size([64]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_2.bn3.weight\n",
      "137 torch.Size([64]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_2.bn3.bias\n",
      "138 torch.Size([64]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_2.bn3.running_mean\n",
      "139 torch.Size([64]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_2.bn3.running_var\n",
      "140 torch.Size([384, 64, 1, 1]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_3.conv1.weight\n",
      "141 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_3.bn1.weight\n",
      "142 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_3.bn1.bias\n",
      "143 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_3.bn1.running_mean\n",
      "144 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_3.bn1.running_var\n",
      "145 torch.Size([384, 1, 3, 3]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_3.conv2.weight\n",
      "146 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_3.bn2.weight\n",
      "147 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_3.bn2.bias\n",
      "148 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_3.bn2.running_mean\n",
      "149 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_3.bn2.running_var\n",
      "150 torch.Size([64, 384, 1, 1]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_3.conv3.weight\n",
      "151 torch.Size([64]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_3.bn3.weight\n",
      "152 torch.Size([64]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_3.bn3.bias\n",
      "153 torch.Size([64]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_3.bn3.running_mean\n",
      "154 torch.Size([64]) --->  module.bottlenecks.Bottlenecks_3.LinearBottleneck3_3.bn3.running_var\n",
      "155 torch.Size([384, 64, 1, 1]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_0.conv1.weight\n",
      "156 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_0.bn1.weight\n",
      "157 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_0.bn1.bias\n",
      "158 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_0.bn1.running_mean\n",
      "159 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_0.bn1.running_var\n",
      "160 torch.Size([384, 1, 3, 3]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_0.conv2.weight\n",
      "161 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_0.bn2.weight\n",
      "162 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_0.bn2.bias\n",
      "163 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_0.bn2.running_mean\n",
      "164 torch.Size([384]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_0.bn2.running_var\n",
      "165 torch.Size([96, 384, 1, 1]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_0.conv3.weight\n",
      "166 torch.Size([96]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_0.bn3.weight\n",
      "167 torch.Size([96]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_0.bn3.bias\n",
      "168 torch.Size([96]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_0.bn3.running_mean\n",
      "169 torch.Size([96]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_0.bn3.running_var\n",
      "170 torch.Size([576, 96, 1, 1]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_1.conv1.weight\n",
      "171 torch.Size([576]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_1.bn1.weight\n",
      "172 torch.Size([576]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_1.bn1.bias\n",
      "173 torch.Size([576]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_1.bn1.running_mean\n",
      "174 torch.Size([576]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_1.bn1.running_var\n",
      "175 torch.Size([576, 1, 3, 3]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_1.conv2.weight\n",
      "176 torch.Size([576]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_1.bn2.weight\n",
      "177 torch.Size([576]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_1.bn2.bias\n",
      "178 torch.Size([576]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_1.bn2.running_mean\n",
      "179 torch.Size([576]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_1.bn2.running_var\n",
      "180 torch.Size([96, 576, 1, 1]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_1.conv3.weight\n",
      "181 torch.Size([96]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_1.bn3.weight\n",
      "182 torch.Size([96]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_1.bn3.bias\n",
      "183 torch.Size([96]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_1.bn3.running_mean\n",
      "184 torch.Size([96]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_1.bn3.running_var\n",
      "185 torch.Size([576, 96, 1, 1]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_2.conv1.weight\n",
      "186 torch.Size([576]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_2.bn1.weight\n",
      "187 torch.Size([576]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_2.bn1.bias\n",
      "188 torch.Size([576]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_2.bn1.running_mean\n",
      "189 torch.Size([576]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_2.bn1.running_var\n",
      "190 torch.Size([576, 1, 3, 3]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_2.conv2.weight\n",
      "191 torch.Size([576]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_2.bn2.weight\n",
      "192 torch.Size([576]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_2.bn2.bias\n",
      "193 torch.Size([576]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_2.bn2.running_mean\n",
      "194 torch.Size([576]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_2.bn2.running_var\n",
      "195 torch.Size([96, 576, 1, 1]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_2.conv3.weight\n",
      "196 torch.Size([96]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_2.bn3.weight\n",
      "197 torch.Size([96]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_2.bn3.bias\n",
      "198 torch.Size([96]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_2.bn3.running_mean\n",
      "199 torch.Size([96]) --->  module.bottlenecks.Bottlenecks_4.LinearBottleneck4_2.bn3.running_var\n",
      "200 torch.Size([576, 96, 1, 1]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_0.conv1.weight\n",
      "201 torch.Size([576]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_0.bn1.weight\n",
      "202 torch.Size([576]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_0.bn1.bias\n",
      "203 torch.Size([576]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_0.bn1.running_mean\n",
      "204 torch.Size([576]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_0.bn1.running_var\n",
      "205 torch.Size([576, 1, 3, 3]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_0.conv2.weight\n",
      "206 torch.Size([576]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_0.bn2.weight\n",
      "207 torch.Size([576]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_0.bn2.bias\n",
      "208 torch.Size([576]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_0.bn2.running_mean\n",
      "209 torch.Size([576]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_0.bn2.running_var\n",
      "210 torch.Size([160, 576, 1, 1]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_0.conv3.weight\n",
      "211 torch.Size([160]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_0.bn3.weight\n",
      "212 torch.Size([160]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_0.bn3.bias\n",
      "213 torch.Size([160]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_0.bn3.running_mean\n",
      "214 torch.Size([160]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_0.bn3.running_var\n",
      "215 torch.Size([960, 160, 1, 1]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_1.conv1.weight\n",
      "216 torch.Size([960]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_1.bn1.weight\n",
      "217 torch.Size([960]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_1.bn1.bias\n",
      "218 torch.Size([960]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_1.bn1.running_mean\n",
      "219 torch.Size([960]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_1.bn1.running_var\n",
      "220 torch.Size([960, 1, 3, 3]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_1.conv2.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221 torch.Size([960]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_1.bn2.weight\n",
      "222 torch.Size([960]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_1.bn2.bias\n",
      "223 torch.Size([960]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_1.bn2.running_mean\n",
      "224 torch.Size([960]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_1.bn2.running_var\n",
      "225 torch.Size([160, 960, 1, 1]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_1.conv3.weight\n",
      "226 torch.Size([160]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_1.bn3.weight\n",
      "227 torch.Size([160]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_1.bn3.bias\n",
      "228 torch.Size([160]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_1.bn3.running_mean\n",
      "229 torch.Size([160]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_1.bn3.running_var\n",
      "230 torch.Size([960, 160, 1, 1]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_2.conv1.weight\n",
      "231 torch.Size([960]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_2.bn1.weight\n",
      "232 torch.Size([960]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_2.bn1.bias\n",
      "233 torch.Size([960]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_2.bn1.running_mean\n",
      "234 torch.Size([960]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_2.bn1.running_var\n",
      "235 torch.Size([960, 1, 3, 3]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_2.conv2.weight\n",
      "236 torch.Size([960]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_2.bn2.weight\n",
      "237 torch.Size([960]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_2.bn2.bias\n",
      "238 torch.Size([960]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_2.bn2.running_mean\n",
      "239 torch.Size([960]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_2.bn2.running_var\n",
      "240 torch.Size([160, 960, 1, 1]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_2.conv3.weight\n",
      "241 torch.Size([160]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_2.bn3.weight\n",
      "242 torch.Size([160]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_2.bn3.bias\n",
      "243 torch.Size([160]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_2.bn3.running_mean\n",
      "244 torch.Size([160]) --->  module.bottlenecks.Bottlenecks_5.LinearBottleneck5_2.bn3.running_var\n",
      "245 torch.Size([960, 160, 1, 1]) --->  module.bottlenecks.Bottlenecks_6.LinearBottleneck6_0.conv1.weight\n",
      "246 torch.Size([960]) --->  module.bottlenecks.Bottlenecks_6.LinearBottleneck6_0.bn1.weight\n",
      "247 torch.Size([960]) --->  module.bottlenecks.Bottlenecks_6.LinearBottleneck6_0.bn1.bias\n",
      "248 torch.Size([960]) --->  module.bottlenecks.Bottlenecks_6.LinearBottleneck6_0.bn1.running_mean\n",
      "249 torch.Size([960]) --->  module.bottlenecks.Bottlenecks_6.LinearBottleneck6_0.bn1.running_var\n",
      "250 torch.Size([960, 1, 3, 3]) --->  module.bottlenecks.Bottlenecks_6.LinearBottleneck6_0.conv2.weight\n",
      "251 torch.Size([960]) --->  module.bottlenecks.Bottlenecks_6.LinearBottleneck6_0.bn2.weight\n",
      "252 torch.Size([960]) --->  module.bottlenecks.Bottlenecks_6.LinearBottleneck6_0.bn2.bias\n",
      "253 torch.Size([960]) --->  module.bottlenecks.Bottlenecks_6.LinearBottleneck6_0.bn2.running_mean\n",
      "254 torch.Size([960]) --->  module.bottlenecks.Bottlenecks_6.LinearBottleneck6_0.bn2.running_var\n",
      "255 torch.Size([320, 960, 1, 1]) --->  module.bottlenecks.Bottlenecks_6.LinearBottleneck6_0.conv3.weight\n",
      "256 torch.Size([320]) --->  module.bottlenecks.Bottlenecks_6.LinearBottleneck6_0.bn3.weight\n",
      "257 torch.Size([320]) --->  module.bottlenecks.Bottlenecks_6.LinearBottleneck6_0.bn3.bias\n",
      "258 torch.Size([320]) --->  module.bottlenecks.Bottlenecks_6.LinearBottleneck6_0.bn3.running_mean\n",
      "259 torch.Size([320]) --->  module.bottlenecks.Bottlenecks_6.LinearBottleneck6_0.bn3.running_var\n",
      "\n",
      "Number of weights:  260\n"
     ]
    }
   ],
   "source": [
    "_trained_keys = []\n",
    "_trained_key_ids = []\n",
    "for i, w in enumerate(trained_weights[:-7]):\n",
    "    _trained_keys.append(trained_keys[i])\n",
    "    _trained_key_ids.append(i)\n",
    "    print(i, w.size(), '---> ', trained_keys[i])\n",
    "    \n",
    "print()\n",
    "print('Number of weights: ', len(_trained_keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_key_map = dict(zip(_trained_keys, _model_keys))\n",
    "trained_key_ids_map = dict(zip(_trained_key_ids, _model_key_ids))\n",
    "\n",
    "for train_key_id, model_key_id in trained_key_ids_map.items():\n",
    "    assert trained_weights[train_key_id].shape == model_weights[model_key_id].shape\n",
    "    \n",
    "for train_key, model_key in trained_key_map.items():\n",
    "    assert trained_state_dict['state_dict'][train_key].shape == model.state_dict()[model_key].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trained_state = trained_state_dict['state_dict']\n",
    "model_state = model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "model_state['layer0.0.conv.0.weight'][0, :, :, :]\n",
    "\n",
    "tensor([[[ 0.0642,  0.0665, -0.0183],\n",
    "         [ 0.1289, -0.0172, -0.0765],\n",
    "         [-0.1314,  0.0287, -0.0152]],\n",
    "\n",
    "        [[-0.0030,  0.0045, -0.0062],\n",
    "         [-0.0078,  0.0550,  0.0823],\n",
    "         [ 0.0269,  0.0041, -0.0504]],\n",
    "\n",
    "        [[ 0.1453, -0.0798,  0.0570],\n",
    "         [ 0.0030, -0.0672, -0.0656],\n",
    "         [ 0.0377, -0.0117,  0.0147]]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_key, model_key in trained_key_map.items():\n",
    "    model_state[model_key] = trained_state[train_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0328, -0.0461,  0.0477],\n",
       "         [-0.0949, -0.0869,  0.1127],\n",
       "         [ 0.0155, -0.0195,  0.0531]],\n",
       "\n",
       "        [[ 0.0586,  0.0218,  0.0724],\n",
       "         [-0.0116, -0.0063,  0.2373],\n",
       "         [ 0.0562,  0.0030,  0.1027]],\n",
       "\n",
       "        [[-0.0158, -0.0735,  0.0536],\n",
       "         [-0.0307, -0.0113,  0.3229],\n",
       "         [-0.0774, -0.1312,  0.0766]]], device='cuda:1')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_state['module.conv1.weight'][0, :, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0328, -0.0461,  0.0477],\n",
       "         [-0.0949, -0.0869,  0.1127],\n",
       "         [ 0.0155, -0.0195,  0.0531]],\n",
       "\n",
       "        [[ 0.0586,  0.0218,  0.0724],\n",
       "         [-0.0116, -0.0063,  0.2373],\n",
       "         [ 0.0562,  0.0030,  0.1027]],\n",
       "\n",
       "        [[-0.0158, -0.0735,  0.0536],\n",
       "         [-0.0307, -0.0113,  0.3229],\n",
       "         [-0.0774, -0.1312,  0.0766]]], device='cuda:1')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_state['layer0.0.conv.0.weight'][0, :, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(model_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0328, -0.0461,  0.0477],\n",
       "         [-0.0949, -0.0869,  0.1127],\n",
       "         [ 0.0155, -0.0195,  0.0531]],\n",
       "\n",
       "        [[ 0.0586,  0.0218,  0.0724],\n",
       "         [-0.0116, -0.0063,  0.2373],\n",
       "         [ 0.0562,  0.0030,  0.1027]],\n",
       "\n",
       "        [[-0.0158, -0.0735,  0.0536],\n",
       "         [-0.0307, -0.0113,  0.3229],\n",
       "         [-0.0774, -0.1312,  0.0766]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()['layer0.0.conv.0.weight'][0, :, :, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Weights and Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Model pre-trained on ImageNet weights\n",
    "pre_trained_state = torch.load('./MobileNetV2.pth.tar')['state_dict']\n",
    "\n",
    "# Modified MobileNet\n",
    "mobile_net = MobileNetV2(params=config)\n",
    "mobile_net_state = mobile_net.state_dict()\n",
    "\n",
    "for train_key, model_key in trained_key_map.items():\n",
    "    mobile_net_state[model_key] = pre_trained_state[train_key]\n",
    "    \n",
    "mobile_net.load_state_dict(mobile_net_state)\n",
    "torch.save(mobile_net.state_dict(), 'MobileNetV2-Pretrained-Weights.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0000,  0.0881,  0.0684],\n",
      "         [ 0.0612, -0.1843, -0.1351],\n",
      "         [ 0.0600,  0.0133, -0.1209]]], device='cuda:1')\n",
      "\n",
      "tensor([[[ 0.0000,  0.0881,  0.0684],\n",
      "         [ 0.0612, -0.1843, -0.1351],\n",
      "         [ 0.0600,  0.0133, -0.1209]]], device='cuda:1')\n",
      "\n",
      "tensor([[[ 0.0000,  0.0881,  0.0684],\n",
      "         [ 0.0612, -0.1843, -0.1351],\n",
      "         [ 0.0600,  0.0133, -0.1209]]])\n"
     ]
    }
   ],
   "source": [
    "print(pre_trained_state['module.bottlenecks.Bottlenecks_0.LinearBottleneck0_0.conv2.weight'][0,...])\n",
    "print()\n",
    "print(mobile_net_state['layer1.0.block.3.weight'][0, ...])\n",
    "print()\n",
    "print(mobile_net.state_dict()['layer1.0.block.3.weight'][0, ...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "children = list(mobile_net.children())\n",
    "len(children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
