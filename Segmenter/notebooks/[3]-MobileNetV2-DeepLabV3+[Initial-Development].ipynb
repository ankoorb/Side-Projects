{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modified MobileNetV2 for DeepLabV3+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_divisible(v, divisor, min_value=None):\n",
    "    \"\"\"\n",
    "    This function makes sure that number of channels number is divisible by 8.\n",
    "    Source: https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n",
    "    \"\"\"\n",
    "    if min_value is None:\n",
    "        min_value = divisor\n",
    "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_v < 0.9 * v:\n",
    "        new_v += divisor\n",
    "    return new_v\n",
    "\n",
    "\n",
    "class ConvBnReLU(nn.Module):\n",
    "    \"\"\"\n",
    "    [CONV]-[BN]-[ReLU6]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, inCh, outCh, stride):\n",
    "        super(ConvBnReLU, self).__init__()\n",
    "        self.inCh = inCh  # Number of input channels\n",
    "        self.outCh = outCh  # Number of output channels\n",
    "        self.stride = stride  # Stride\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(self.inCh, self.outCh, 3, stride=self.stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(outCh),\n",
    "            nn.ReLU6(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class InvertedResidual(nn.Module):\n",
    "    \"\"\"\n",
    "    [EXP:CONV_1x1-BN-ReLU6]-[DW:CONV_3x3-BN-ReLU6]-[PW:CONV_1x1-BN] with identity shortcut \n",
    "    and dilation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, inCh, outCh, t, s, r):\n",
    "        super(InvertedResidual, self).__init__()\n",
    "        self.inCh = inCh\n",
    "        self.outCh = outCh\n",
    "        self.t = t  # t: expansion factor\n",
    "        self.r = r  # r: dilation\n",
    "        if self.r > 1:\n",
    "            self.s = 1  # s: Stride\n",
    "            self.padding = self.r  # Atrous Conv padding same as dilation rate\n",
    "        else:\n",
    "            self.s = s  # s: Stride\n",
    "            self.padding = 1\n",
    "        self.identity_shortcut = (self.inCh == self.outCh) and (self.s == 1)  # L:506 Keras official code\n",
    "\n",
    "        # Bottleneck block\n",
    "        self.block = nn.Sequential(\n",
    "            # Expansition Conv\n",
    "            nn.Conv2d(self.inCh, self.t * self.inCh, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(self.t * self.inCh),\n",
    "            nn.ReLU6(inplace=True),\n",
    "\n",
    "            # Depthwise Conv\n",
    "            nn.Conv2d(self.t * self.inCh, self.t * self.inCh, kernel_size=3, stride=self.s, padding=self.padding, \n",
    "                      dilation=self.r, groups=self.t * self.inCh, bias=False),\n",
    "            nn.BatchNorm2d(self.t * self.inCh),\n",
    "            nn.ReLU6(inplace=True),\n",
    "\n",
    "            # Pointwise Linear Conv (Projection): i.e. No non-linearity\n",
    "            nn.Conv2d(self.t * self.inCh, self.outCh, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(self.outCh),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.identity_shortcut:\n",
    "            return x + self.block(x)\n",
    "        else:\n",
    "            return self.block(x)\n",
    "\n",
    "\n",
    "class PointwiseConv(nn.Module):\n",
    "    def __init__(self, inCh, outCh):\n",
    "        super(PointwiseConv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(inCh, outCh, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(outCh),\n",
    "            nn.ReLU6(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "# MobileNetV2\n",
    "class MobileNetV2(nn.Module):\n",
    "    \"\"\"\n",
    "    MobileNetV2 feature extractor modified to include dilation for DeepLabV3+. \n",
    "    NOTE: Last conv Layer and classification layer removed.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, params):\n",
    "        super(MobileNetV2, self).__init__()\n",
    "        self.params = params\n",
    "        self.first_inCh = 3\n",
    "\n",
    "        self.c = [_make_divisible(c * self.params.alpha, 8) for c in self.params.c]\n",
    "        \n",
    "        # Layer-0\n",
    "        self.layer0 = nn.Sequential(ConvBnReLU(self.first_inCh, self.c[0], self.params.s[0]))\n",
    "\n",
    "        # Layer-1\n",
    "        self.layer1 = self._make_layer(self.c[0], self.c[1], self.params.t[1], self.params.s[1], \n",
    "                                       self.params.n[1], self.params.r[1])\n",
    "\n",
    "        # Layer-2: Image size: 512 -> [IRB-2] -> Output size: 128 (low level feature: 128 * 4 = 512)\n",
    "        self.layer2 = self._make_layer(self.c[1], self.c[2], self.params.t[2], self.params.s[2], \n",
    "                                       self.params.n[2], self.params.r[2])\n",
    "\n",
    "        # Layer-3\n",
    "        self.layer3 = self._make_layer(self.c[2], self.c[3], self.params.t[3], self.params.s[3], \n",
    "                                       self.params.n[3], self.params.r[3])\n",
    "\n",
    "        # Layer-4\n",
    "        self.layer4 = self._make_layer(self.c[3], self.c[4], self.params.t[4], self.params.s[4], \n",
    "                                       self.params.n[4], self.params.r[4])\n",
    "\n",
    "        # Layer-5: Image size: 512 -> [IRB-5] -> Output size: 32, so output stride = 16 achieved\n",
    "        self.layer5 = self._make_layer(self.c[4], self.c[5], self.params.t[5], self.params.s[5], \n",
    "                                       self.params.n[5], self.params.r[5])\n",
    "\n",
    "        # Layer-6: Apply dilation rate = 2\n",
    "        self.layer6 = self._make_layer(self.c[5], self.c[6], self.params.t[6], self.params.s[6], \n",
    "                                       self.params.n[6], self.params.r[6])\n",
    "\n",
    "        # Layer-7: Apply dilation rate = 2\n",
    "        self.layer7 = self._make_layer(self.c[6], self.c[7], self.params.t[7], self.params.s[7], \n",
    "                                       self.params.n[7], self.params.r[7])\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _make_layer(self, inCh, outCh, t, s, n, r):\n",
    "        layers = []\n",
    "        for i in range(n):\n",
    "            # First layer of each sequence has a stride s and all others use stride 1\n",
    "            if i == 0:\n",
    "                layers.append(InvertedResidual(inCh, outCh, t, s, r))\n",
    "            else:\n",
    "                layers.append(InvertedResidual(inCh, outCh, t, 1, r))\n",
    "\n",
    "            # Update input channel for next IRB layer in the block\n",
    "            inCh = outCh\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        low_level_features = self.layer2(x)  # [512, 512]/4 = [128, 128] \n",
    "        x = self.layer3(low_level_features)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        x = self.layer6(x)\n",
    "        x = self.layer7(x)\n",
    "        return x, low_level_features\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "                \n",
    "                \n",
    "def MobileNet():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atrous Spatial Pyramid Pooling (ASPP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AtrousConvBnRelu(nn.Module):\n",
    "    \"\"\"\n",
    "    [Atrous CONV]-[BN]-[ReLU]\n",
    "    \"\"\"\n",
    "    def __init__(self, inCh, outCh, dilation=1):\n",
    "        super(AtrousConvBnRelu, self).__init__()\n",
    "        self.inCh = inCh\n",
    "        self.outCh = outCh\n",
    "        self.dilation = dilation\n",
    "        self.kernel = 1 if self.dilation == 1 else 3\n",
    "        self.padding = 0 if self.dilation == 1 else self.dilation\n",
    "        self.atrous_conv = nn.Sequential(\n",
    "            nn.Conv2d(self.inCh, self.outCh, self.kernel, stride=1, \n",
    "                      padding=self.padding, dilation=self.dilation, bias=False), \n",
    "            nn.BatchNorm2d(self.outCh),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.atrous_conv(x)\n",
    "    \n",
    "\n",
    "class ASPP(nn.Module):\n",
    "    \"\"\"\n",
    "    Atrous Spatial Pyramid Pooling\n",
    "    \n",
    "    Ref(s): https://github.com/rishizek/tensorflow-deeplab-v3-plus/blob/master/deeplab_model.py\n",
    "    and https://github.com/chenxi116/DeepLabv3.pytorch/blob/master/deeplab.py\n",
    "    \"\"\"\n",
    "    def __init__(self, inCh, outCh):\n",
    "        super(ASPP, self).__init__()\n",
    "        self.rates = [1, 6, 12, 18] # for output stride 16\n",
    "        self.inCh = inCh\n",
    "        self.outCh = outCh\n",
    "        \n",
    "        # ASPP layers\n",
    "        # (a) One 1x1 convolution and three 3x3 convolutions with rates = (6, 12, 18)\n",
    "        self.conv_1x1_0 = AtrousConvBnRelu(inCh=self.inCh, outCh=self.outCh, \n",
    "                                           dilation=self.rates[0])\n",
    "        self.conv_3x3_1 = AtrousConvBnRelu(inCh=self.inCh, outCh=self.outCh, \n",
    "                                           dilation=self.rates[1])\n",
    "        self.conv_3x3_2 = AtrousConvBnRelu(inCh=self.inCh, outCh=self.outCh, \n",
    "                                           dilation=self.rates[2])\n",
    "        self.conv_3x3_3 = AtrousConvBnRelu(inCh=self.inCh, outCh=self.outCh, \n",
    "                                           dilation=self.rates[3])\n",
    "        \n",
    "        # (b) The image-level features\n",
    "        # Global Average Pooling\n",
    "        self.global_avg_pooling = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "        \n",
    "        # CONV-BN-ReLU after Global Average Pooling\n",
    "        self.conv_bn_relu_4 = nn.Sequential(\n",
    "            nn.Conv2d(self.inCh, self.outCh, kernel_size=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(self.outCh),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # CONV-BN-ReLU after Concatenation. NOTE: 5 Layers are concatenated\n",
    "        self.conv_bn_relu_5 = nn.Sequential(\n",
    "            nn.Conv2d(self.outCh * 5, self.outCh, kernel_size=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(self.outCh),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x0 = self.conv_1x1_0(x)  # size: [1, outCh, fs, fs]\n",
    "        x1 = self.conv_3x3_1(x)  # size: [1, outCh, fs, fs]\n",
    "        x2 = self.conv_3x3_2(x)  # size: [1, outCh, fs, fs]\n",
    "        x3 = self.conv_3x3_3(x)  # size: [1, outCh, fs, fs]\n",
    "        \n",
    "        # Global Average Pooling, CONV-BN-ReLU and upsample\n",
    "        global_avg_pool = self.global_avg_pooling(x)\n",
    "        \n",
    "        x4 = self.conv_bn_relu_4(global_avg_pool)\n",
    "        \n",
    "        upsample = F.interpolate(x4, size=(x.size(2), x.size(3)), mode='bilinear', \n",
    "                                 align_corners=True)\n",
    "        \n",
    "        # Concatinate\n",
    "        x_concat = torch.cat([x0, x1, x2, x3, upsample], dim=1) # size: [1, 5 * outCh, fs, fs]\n",
    "        \n",
    "        # CONV-BN-ReLU after concatination\n",
    "        out = self.conv_bn_relu_5(x_concat)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Decoder for DeepLabV3+\n",
    "    \"\"\"\n",
    "    def __init__(self, low_level_inch, low_level_outch, inCh, outCh, n_classes):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.low_level_inch = low_level_inch\n",
    "        self.low_level_outch = low_level_outch # 48 (or lower for speed)\n",
    "        self.inCh = inCh\n",
    "        self.outCh = outCh\n",
    "        self.n_classes = n_classes\n",
    "        \n",
    "        # 1x1 Conv with BN and ReLU for low level features\n",
    "        self.conv_1x1_bn_relu = nn.Sequential(\n",
    "            nn.Conv2d(self.low_level_inch, self.low_level_outch, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(self.low_level_outch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Conv block with BN and ReLU (paper suggests to use a few 3x3 Convs, but using only 1\n",
    "        # for speed improvement) and final Conv 1x1 \n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.Conv2d(self.inCh + self.low_level_outch, self.outCh, kernel_size=3, stride=1, padding=1, \n",
    "                      bias=False),\n",
    "            nn.BatchNorm2d(self.outCh),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            # For reducing number of channels\n",
    "            nn.Conv2d(self.outCh, self.n_classes, kernel_size=1, stride=1, bias=False)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, low_level_features):\n",
    "        \n",
    "        # Low level features from MobileNetV2\n",
    "        low_level_features = self.conv_1x1_bn_relu(low_level_features)\n",
    "        \n",
    "        # Upsample features from ASPP by 4\n",
    "        x = F.interpolate(x, scale_factor=4, mode='bilinear', align_corners=True)\n",
    "        \n",
    "        # Concatinate\n",
    "        x_concat = torch.cat([x, low_level_features], dim=1)\n",
    "        \n",
    "        # Final Convolution\n",
    "        out = self.conv_block(x_concat)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepLabV3+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepLabV3plus(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(DeepLabV3plus, self).__init__()\n",
    "        self.config = config\n",
    "        \n",
    "        # Base Network\n",
    "        self.base = MobileNetV2(params=self.config)\n",
    "        \n",
    "        # ASPP Module\n",
    "        self.aspp = ASPP(inCh=self.config.aspp_inch, \n",
    "                         outCh=self.config.aspp_outch)\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = Decoder(low_level_inch=self.config.low_level_inCh, \n",
    "                               low_level_outch=self.config.low_level_outCh, \n",
    "                               inCh=self.config.in_channels, \n",
    "                               outCh=self.config.out_channels,\n",
    "                               n_classes=self.config.n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Extract features from base network\n",
    "        base_out, low_level_features = self.base(x)\n",
    "        \n",
    "        # Pool base network output using Atrous Spatial Pyramid Pooling\n",
    "        aspp_out = self.aspp(base_out)\n",
    "        \n",
    "        # Use decoder to obtain object boundaries\n",
    "        decoder_out = self.decoder(aspp_out, low_level_features)\n",
    "        \n",
    "        # Upsample features from decoder by 4\n",
    "        out = F.interpolate(decoder_out, scale_factor=4, mode='bilinear', align_corners=True)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config():\n",
    "    \"\"\"\n",
    "    Configuration for training DeepLabV3+\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # MobileNetV2 parameters\n",
    "        # ----------------------\n",
    "        # Conv and Inverted Residual Parameters: Table-2 (https://arxiv.org/pdf/1801.04381.pdf)\n",
    "        self.t = [1, 1, 6, 6, 6, 6, 6, 6]  # t: expansion factor\n",
    "        self.c = [32, 16, 24, 32, 64, 96, 160, 320]  # c: Output channels\n",
    "        self.n = [1, 1, 2, 3, 4, 3, 3, 1]  # n: Number of times layer is repeated\n",
    "        self.s = [2, 1, 2, 2, 2, 1, 2, 1]  # s: Stride\n",
    "        self.r = [1, 1, 1, 1, 1, 1, 2, 2]  # r: Dilation (added to take care of dilation)\n",
    "        # Width multiplier: Controls the width of the network\n",
    "        self.alpha = 0.5\n",
    "        \n",
    "        # ASPP Parameters\n",
    "        # ---------------\n",
    "        self.aspp_inch = int(self.alpha * self.c[-1])  # Width multiplier * 320\n",
    "        self.aspp_outch = int(self.alpha * 256)  # Width multiplier * 256\n",
    "        \n",
    "        # Decoder Parameters\n",
    "        # ------------------\n",
    "        self.n_classes = 20\n",
    "        self.low_level_inCh = int(self.alpha * self.c[3])  # Width multiplier * 32 \n",
    "        self.low_level_outCh = int(2 * self.low_level_inCh)  # 2 * low level features channels\n",
    "        self.in_channels = int(self.alpha * 256) # Width multiplier * 256\n",
    "        self.out_channels = int(self.alpha * 256) # Width multiplier * 256\n",
    "        \n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check DeepLabV3+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape:  torch.Size([1, 20, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "deeplab = DeepLabV3plus(config=config)\n",
    "deeplab.eval()\n",
    "\n",
    "# Input Image\n",
    "x = torch.randn([1, 3, 512, 512])\n",
    "\n",
    "y = deeplab(x)\n",
    "print('output shape: ', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform DeepLabV3+ Output to Class Map (for Cityscapes Data) \n",
    "\n",
    "- DeepLabV3+ Output size: `[20, 512, 512]`\n",
    "- Transformed Class Map size: `[1024, 2048]`\n",
    "\n",
    "#### For App, use the input image size instead of hard-coded numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logits_to_class_map(logits):\n",
    "    \"\"\"\n",
    "    Transform DeepLabV3+ Output to trainId map (class map)\n",
    "    \n",
    "    logits: PyTorch tensor, size: [1, 20, h, w]. It is the output \n",
    "        of DeepLabV3+ model.\n",
    "    \"\"\"\n",
    "    upsample = F.interpolate(logits, size=(1024, 2048), mode='bilinear', \n",
    "                             align_corners=False)\n",
    "    \n",
    "    # [1, 20, 1024, 2048] -> [20, 1024, 2048]\n",
    "    upsample = upsample.squeeze(0)\n",
    "    \n",
    "    # Find indices with maximum value\n",
    "    out = torch.argmax(upsample, dim=0)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsampled output shape:  torch.Size([1, 20, 1024, 2048])\n",
      "Upsampled output shape:  torch.Size([20, 1024, 2048])\n",
      "Class map shape:  torch.Size([1024, 2048])\n"
     ]
    }
   ],
   "source": [
    "out = torch.randn([1, 20, 512, 512])\n",
    "u_out = F.interpolate(out, size=(1024, 2048), mode='bilinear', \n",
    "                      align_corners=False)\n",
    "\n",
    "print('Upsampled output shape: ', u_out.shape)\n",
    "\n",
    "u_out = u_out.squeeze(0)\n",
    "print('Upsampled output shape: ', u_out.shape)\n",
    "\n",
    "c_map = torch.argmax(u_out, dim=0)\n",
    "print('Class map shape: ', c_map.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2,  6, 18,  4, 11, 13,  3, 10,  7,  8, 17, 14,  5, 19,  0, 12,  1,  9,\n",
      "        15, 16])\n"
     ]
    }
   ],
   "source": [
    "print(torch.unique(c_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
